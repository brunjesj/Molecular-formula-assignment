###############################################################################
#This provides a graphical user interface to perform all calculations. 
#Results from each step are being exported into the local R environment.
#
# Work in progress. No diagnostic plots and less options compared to running the functions individually
###############################################################################
library(bit64)
library(shiny)
library(data.table)
library(quantreg)
library(dplyr)
library(DT)
library(plotly)
library(mgcv)
library(igraph)

###############################################################################
#               Panel 1:  Functions & Shiny UI/Server Code                    #
#                    (Instrument Blanks Noise Removal)                    #
###############################################################################

# -- Panel 1 Functions --
# Set maximum file size (adjust as needed)
options(shiny.maxRequestSize = 4096 * 4096 * 4096)

calculate_noise <- function(blank, approach=1, confidence_level = 0.998, MDL_level = 2.5){
  colnames(blank)[1] <- "m.z"
  colnames(blank)[2] <- "I"
  blank$I <- as.numeric(blank$I)

  blank[, nominal_mass := floor(m.z + 0.5)]

  if (approach == 1) {
    # Use Riedel-based formula (t-statistic with user-defined confidence level)
    res <- blank[, .(
      MDL = qt(confidence_level, df = .N - 1) * sd(I) + mean(I)
    ), by = nominal_mass]
  }
  if(approach ==2){
    # Use Merder 2020 approach with a fixed factor * sd + mean
    res <-   blank[, .(
      MDL = mean(I, na.rm = TRUE) + MDL_level * sd(I, na.rm = TRUE)
    ), by = nominal_mass]
  }
  if(approach ==3){
    #this would be a quantile-based approach where 99% (chosen confidence) of the signal intensities detected in the blank would be excluded
    #for each nominal mass
    res <-  blank[, .(
      MDL = quantile(I, probs = confidence_level, na.rm = TRUE)
    ), by = nominal_mass]
  }
  return(res)
}

# Function to remove outliers in ResPow based on quantile regression
ResPow_outlier <- function(dataset, showplot = F) {
  colnames(dataset)[1] <- "m.z"

  nrow_initial <- nrow(dataset)
  
  dataset <- na.omit(dataset, cols = c("Res.", "m.z"))
  
  # Fit quantile regression model
  d <- rq(log(Res.) ~ log(m.z), data = dataset, method = "fn")
  
  # Density of residuals
  dens <- density(d$residuals)
  
  # Identify threshold e in a single chained operation:
  e <- data.table(x = dens$x[-1], y = diff(dens$y))[
    x > 0
  ][
    which.min(y):.N
  ][
    y > 0, x[1]
  ]
  
  # If no threshold is found, use Inf
  if (is.na(e)) e <- Inf
  
  if(showplot == T){
    plot <- plot_ly (type = "scatter", mode = "markers")
    plot <- plot %>% add_trace(x = dataset$m.z, y = dataset$Res., name = "kept")
    
    removed <-dataset[which(d$residuals > abs(e))]
    
    plot <- plot %>% add_trace(x = removed$m.z, y = removed$Res., name = "removed")
    plot <- plot %>% layout(xaxis = list(title = "m/z"), yaxis = list ( title = "Resolution"))
    print(plot)
  }

  

  # Return only rows whose residuals are within Â±e
  dataset <-dataset[which(d$residuals <= abs(e))]
  nrow_after <- nrow(dataset)
  message(paste0("Removed ",nrow_initial-nrow_after, " outlier entries"))
  dataset[, Res. := NULL]
  
}

# Function to process samples and remove peaks below MDL
process_samples_MDL <- function(sample, MDL_master, remove_resolution_outliers = T
) {
  #change integer 64 into numeric for intensity
  colnames(sample)[1] <- "m.z"
  colnames(sample)[2] <- "I"
  sample[, I := as.numeric(I)]
  
  #Calculate nominal_mz
  sample[, nominal_mass := floor(m.z + 0.5)]
  
  if (any(colnames(sample)=="Res." & remove_resolution_outliers ==T)){
    # 3. Merge, then filter to keep only rows above MDL, 
    #    and pick the necessary columns in a single step.
    setkey(sample, nominal_mass)
    setkey(MDL_master, nominal_mass)
    
    # Filter sample based on MDL
    sample[MDL_master, on = "nominal_mass"][I >= MDL,
                                            .(m.z, I, MDL, Res.)] |>
      ResPow_outlier()
  }else {
    
    setkey(sample, nominal_mass)
    setkey(MDL_master, nominal_mass)
    
    # Filter sample based on MDL
    sample[MDL_master, on = "nominal_mass"][I >= MDL,
                                            .(m.z, I, MDL)]
  }
}

# -- Panel 1 UI --
# -- Panel 1 UI --
panel1_ui <- fluidPage(
  titlePanel("Instrument Blanks Noise Removal"),
  
  sidebarLayout(
    sidebarPanel(
      fileInput("blanks_files", "Select Instrument blank file(s):", 
                multiple = TRUE, accept = c(".csv")),
      fileInput("samples_files", "Select sample files:", 
                multiple = TRUE, accept = c(".csv")),
      
      # Radio buttons to select the approach
      radioButtons(
        inputId = "approach", 
        label = "Select MDL calculation approach:",
        choices = c("Riedel 2014 approach" = 1, "Merder 2020 approach" = 2),
        selected = 1 
      ),
      
      # Conditional panel for inputs relevant only to Riedel 2014 approach
      conditionalPanel(
        condition = "input.approach == '1'",
        numericInput("confidence_level", 
                     "Confidence Level:", 
                     value = 0.998, min = 0, max = 1, step = 0.001)
      ),
      
      # Conditional panel for inputs relevant only to Merder 2020 approach
      conditionalPanel(
        condition = "input.approach == '2'",
        numericInput("MDL_level", 
                     "MDL_level:", 
                     value = 2.5, min = 1, step = 0.1)
      ),
      checkboxInput("remove_resolution_outliers", "Remove resolution outliers", value = TRUE),
      
      actionButton("calculate", "Calculate", class = "btn-lg btn-success"),
      downloadButton("download_MDL", "Download as .rds")  ,
      
    ),
    
    mainPanel(
      h4("Blanks Data Preview (First File)"),
      tableOutput("blanks_preview"),
      h4("Samples Data Preview (First File)"),
      tableOutput("samples_preview"),
      h4("Overview processed samples"),
      tableOutput("overview")
    )
  )
)

# -- Panel 1 Server --
panel1_server <- function(input, output, session) {
  
  blanks_data <- reactive({
    req(input$blanks_files)
    lapply(input$blanks_files$datapath, fread)
  })
  
  samples_data <- reactive({
    req(input$samples_files)
    samples <- lapply(input$samples_files$datapath, fread)
    names(samples) <- tools::file_path_sans_ext(basename(input$samples_files$name))
    samples
  })
  
  samples_MDL <- eventReactive(input$calculate, {
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)

    
    req(blanks_data(), samples_data())
    
    progress1 <- Progress$new(session, min = 0, max = length(blanks_data()))
    on.exit(progress1$close())

    #blank_list <- blanks_data()
    #sample_list <- samples_data()
    
    # Initialize progress bar

    
    
    # Step 1: Compute MDL_master based on user-selected approach
    MDL_master <- lapply(seq_along(blanks_data()), function(i) {
      progress1$set(value = i, message = "Processing blanks", detail = paste0("Blank ", i, " of ", length(blanks_data())))
      
      
      calculate_noise(blanks_data()[[i]], approach =  as.numeric(input$approach),
                      confidence_level =  input$confidence_level,
                      MDL_level =  input$MDL_level) 
     
    }) %>% rbindlist()
    

     MDL_master <- MDL_master[order(-MDL), .SD[1], by = nominal_mass]
     MDL_master[, MDL := round(MDL)]
    
     progress1$close()
    
      #Initialize progress bar
     progress2 <- Progress$new(session, min = 0, max = length(samples_data()))
     on.exit(progress2$close())
    
    
    #  Process samples
     processed_samples <- lapply(seq_along(samples_data()), function(i) {
       progress2$set(value = i, message = "Processing samples", detail = paste0("Sample ", i, " of ", length(samples_data())))
       sample <- samples_data()[[i]]
       process_samples_MDL(
         sample      = samples_data()[[i]],
         MDL_master  = MDL_master,
         input$remove_resolution_outliers
       )
    
     })
    
     names(processed_samples) <- names(samples_data())
     #progress2$close()
     # Export processed_samples to the global environment
     assign("samples_MDL", processed_samples, envir = .GlobalEnv)
     gc ()

     output$download_MDL<- downloadHandler(
       filename = function() {
         paste("Noise_cleaned_samples", Sys.Date(), ".rds", sep = "")
       },
       content = function(file) {
         saveRDS(processed_samples, file)
       }
     )
     removeNotification(notification_id)
     
     processed_samples
  })
  
  overview_data <- eventReactive(input$calculate, {
    req(samples_MDL())
    #sample_list <- samples_data()
    #processed_samples <- samples_MDL()
    
    overview <- data.table(
      Sample_Name = names(samples_data()),
      Rows_Before = sapply(samples_data(), nrow),
      Rows_After = sapply(samples_MDL(), nrow),
      Min_mz = sapply(samples_MDL(), function(x) min(x$m.z, na.rm = TRUE)),
      Max_mz = sapply(samples_MDL(), function(x) max(x$m.z, na.rm = TRUE))
    )
    
    return(overview)
  })
  
  
   # Render table for blanks_data head
  output$blanks_preview <- renderTable({
    req(blanks_data())
    head(blanks_data()[[1]])
  })
  
  # Render table for samples_data head
  output$samples_preview <- renderTable({
    req(samples_data())
    head(samples_data()[[1]])
  })



  
  output$overview <- renderTable({
    req(overview_data())
    overview_data()
  })
}


###############################################################################
#               Panel 2:  Functions & Shiny UI/Server Code                    #
#                      (Molecular Formula Generator)                          #
###############################################################################

isotope_combinations <- function(formulas_dt, mass_range,
                                 mass_C, mass_H, mass_O, mass_N, mass_S, mass_P) {
  # Construct a grid for all possible isotopes (within the defined maxima).
  isotope_grid <- CJ(
    O_18 = 0:max(formulas_dt$max_O18),
    C_13 = 0:max(formulas_dt$max_C13),
    S_34 = 0:max(formulas_dt$max_S34)
  )
  
  # Only keep relevant combinations:
  #  - Single extra isotope (O_18, S_34, or C_13)
  #    OR a double 13C (C_13 == 2) with no O_18 / S_34
  isotope_grid <- isotope_grid[
    (O_18 + S_34 + C_13 == 1) | (C_13 == 2 & O_18 == 0 & S_34 == 0)
  ]
  
  # Expand the formula set
  expanded_formulas <- formulas_dt[rep(seq_len(.N), each = nrow(isotope_grid))]
  expanded_isotopes <- isotope_grid[rep(seq_len(nrow(isotope_grid)), times = formulas_dt[ , .N])]
  combined_formulas <- cbind(expanded_formulas, expanded_isotopes)
  
  # Only valid if isotopes actually exist in the formula
  combined_formulas <- combined_formulas[
    (C_13 > 0 & O_18 == 0 & S_34 == 0) |
      ((S_34 > 0 & S > 0) | (O_18 > 0 & O > 0))
  ]
  
  # Recompute m/z for these isotopes
  combined_formulas[ ,
                     mz := C * mass_C + H * mass_H + O * mass_O + N * mass_N + S * mass_S + P * mass_P +
                       C_13 * (13.00335540 - mass_C) +
                       O_18 * (17.99915960 - mass_O) +
                       S_34 * (33.96786690 - mass_S)
  ]
  
  # Keep only those within the requested m/z range
  combined_formulas[mz >= mass_range[1] & mz <= mass_range[2]]
}


generate_formulas <- function(C_range = 1:50, H_range = 2:120, O_range = 0:50,
                              N_range = 0:4, S_range = 0:2, P_range = 0:1,
                              mass_range = c(50, 1000), HC = c( 0.2, 3), OC = c(0, 1.2), insert_isotopes = T) {
  
  # Define element masses in one place
  mass_C  <- 12
  mass_H  <- 1.00782503
  mass_O  <- 15.99491463
  mass_N  <- 14.00307400
  mass_S  <- 31.97207117
  mass_P  <- 30.97376203
  
  # Create the grid of C, N, S, P and apply basic filters
  dt <- CJ(C = C_range, N = N_range, S = S_range, P = P_range)[
    C > 0 &
      (N / C) <= 1.3 & (S / C) <= 0.8 & (P / C) <= 0.3 &
      !(N > 1 & (S + P > 0)) &
      !(N != 0 & S != 0 & P != 0) &
      !(S + P > 2) &
      !(N == 1 & (S > 1 | P > 1))
  ]
  
  # Precompute min and max for H and O based on rules
  dt[ , `:=`(
    H_min = pmax(ceiling(HC[1] * C), H_range[1]),
    H_max = pmin(floor(HC[2] * C), max(H_range)),
    O_max = pmin(floor(OC[2] * C), max(O_range))
  )]
  
  # Construct possible (H, O) combinations
  results <- dt[ , {
    if (H_min <= H_max) {
      H_values <- H_min:H_max
      O_values <- seq.int(0, O_max)
      H_O_dt <- CJ(H = H_values, O = O_values)[
        (H / C) >= HC[1] & (H / C) <= HC[2] & (O / C) >= OC[1] & (O / C) <= OC[2]
      ]
    } else {
      H_O_dt <- NULL
    }
    H_O_dt
  }, by = .(C, N, S, P)]
  
  # Compute DBE and valence, then subset
  results[ , `:=`(
    DBE    = 1 + (2 * C - H + N + P) / 2,
    valence = C * 4 + H * 1 + O * 2 + N * 3 + S * 2 + P * 5
  )]
  results <- results[
    DBE >= 0 & DBE %% 1 == 0 &
      valence %% 2 == 0
  ][ , c("DBE", "valence") := NULL]  # drop columns right after filtering
  
  # Compute final m/z
  results[ ,
           mz := C * mass_C + H * mass_H + O * mass_O + N * mass_N + S * mass_S + P * mass_P
  ]
  results <- results[mz >= mass_range[1] & mz <= mass_range[2]]
  
  # Insert isotopes if needed
  if (isTRUE(insert_isotopes)) {
    results[ , `:=`(
      max_O18 = pmin(1, O),
      max_C13 = pmin(2, C),
      max_S34 = pmin(1, S)
    )]
    
    # Reuse the pre-defined function
    results_isotopes <- isotope_combinations(
      formulas_dt = results,
      mass_range  = mass_range,
      mass_C      = mass_C,
      mass_H      = mass_H,
      mass_O      = mass_O,
      mass_N      = mass_N,
      mass_S      = mass_S,
      mass_P      = mass_P
    )
    results <- rbind(results, results_isotopes, use.names = TRUE, fill = TRUE)
    
  } else {
    # If not inserting isotopes, fill with zeros
    results[ , c("O_18", "C_13", "S_34") := 0]
  }
  
  # Final columns, replace NAs, and sort
  results <- results[ , .(
    C, H, O, N, S, P,
    C_13      = ifelse(is.na(C_13), 0, C_13),
    O_18      = ifelse(is.na(O_18), 0, O_18),
    S_34      = ifelse(is.na(S_34), 0, S_34),
    calculated_m.z = round(mz,8)
  )]
  
  setorder(results, calculated_m.z)
  gc()
  return(results)
}


# -- Panel 2 UI --
panel2_ui <- fluidPage(
  titlePanel("Molecular Formula Generator"),
  sidebarLayout(
    sidebarPanel(
      actionButton("calc_button", "Calculate Formulas", class = "btn-lg btn-success"),
      sliderInput("C_range", "C Range:", min = 1, max = 100, value = c(1, 50)),
      sliderInput("H_range", "H Range:", min = 1, max = 200, value = c(2, 120)),
      sliderInput("O_range", "O Range:", min = 0, max = 100, value = c(0, 50)),
      sliderInput("N_range", "N Range:", min = 0, max = 10, value = c(0, 4)),
      sliderInput("S_range", "S Range:", min = 0, max = 5, value = c(0, 2)),
      sliderInput("P_range", "P Range:", min = 0, max = 5, value = c(0, 1)),
      sliderInput("mass_range", "Mass Range:", min = 0, max = 2000, value = c(90, 1000)),
      sliderInput("HC", "H/C Range:", min = 0, max = 5, value = c(0.2, 3), step = 0.1),
      sliderInput("OC", "O/C Range:", min = 0, max = 4, value = c(0, 1.2), step = 0.1),
      checkboxInput("insert_isotopes", "Insert Isotopes", value = TRUE),

      downloadButton("download_csv_formulas", "Download CSV")  
    ),
    mainPanel(
      DTOutput("results_table"),
      verbatimTextOutput("calc_message")
    )
  )
)

# -- Panel 2 Server --
panel2_server <- function(input, output, session) {
  
  results <- eventReactive(input$calc_button, {
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    out <- generate_formulas(
      C_range = input$C_range[1]:input$C_range[2],
      H_range = input$H_range[1]:input$H_range[2],
      O_range = input$O_range[1]:input$O_range[2],
      N_range = input$N_range[1]:input$N_range[2],
      S_range = input$S_range[1]:input$S_range[2],
      P_range = input$P_range[1]:input$P_range[2],
      mass_range = input$mass_range,
      HC = input$HC,
      OC = input$OC,
      insert_isotopes = input$insert_isotopes
    )
    removeNotification(notification_id)
    # Download handler for CSV file
    output$download_csv_formulas <- downloadHandler(
      filename = function() {
        paste("molecular_formulas", Sys.Date(), ".csv", sep = "")
      },
      content = function(file) {
        fwrite(out, file)
      }
    )
    out
  })
  
  output$results_table <- renderDT({
    head(results())
  })
  
  observeEvent(input$calc_button, {
    assign("molecular_formulas", results(), envir = .GlobalEnv)
    output$calc_message <- renderText({
      "Calculation complete. Results saved to 'formulas' in your R environment."
    })
  })
  
  
}


###############################################################################
#               Panel 3:  Functions & Shiny UI/Server Code                    #
#                      (MZ Recalibration Tool)                                #
###############################################################################

#still performs poorly in areas outside of calibration.

# -- Panel 3 Functions --

mz_recalibration <- function(
    formulas,
    spectrum,
    ppm_tolerance   = 0.5,
    ion             = 1.007825032 + -1 * 0.00054857990907,
    S_MDL_limit     = 2,
    hom_member_min  = 2,
    showplot = F,
    samplename= ""
) {
  SSE_1 <- 0
  SSE_2 <- 0
  plot <- plot_ly(type = "scatter", mode = "text",
                  x = 1, y = 1, text = "Not enough points")%>%
    layout(title = samplename, xaxis = list(title = "m/z"),
           yaxis = list(title = "ppm"))
  

  
  data <- copy(spectrum)
  
  data_original <- copy (data)
  
  tryCatch({
    
    
    # 2) Filter data by I / MDL > S_MDL_limit directly
    data <- data[I / MDL > S_MDL_limit]
    
    # 3) Assign formulas and filter by atomic composition
    out <- formula_assignment_multi_intensity(
      formulas,
      data,
      ppm_tolerance = ppm_tolerance,
      ion           = ion,
      threshold = 200,
      delete_singlets = F,
      delete_MF_without_connection = F
    )
    out[, homologues_membership := NULL]
    
    # 4) Homologue-series calculation only if we still have enough data
    if (nrow(out) > 20) {
      out <- calculate_connections(out)[homologues_membership >= hom_member_min]
    }
    
    # 5) If the filtered data is still sufficiently large, proceed with outlier filtering + GAM model
    if (nrow(out) > 20) {
      
      # -- Quantile-based filtering in data.table style
      Q1   <- quantile(out$ppm, 0.25)
      Q3   <- quantile(out$ppm, 0.75)
      IQRv <- Q3 - Q1
      out  <- out[ppm > (Q1 - 1.5 * IQRv) & ppm < (Q3 + 1.5 * IQRv)]
      
      SSE_1 <- round(sum(out$ppm^2),2)
      
      # -- Fit a GAM model
      gam_model <- gam(ppm ~ s(m.z, bs = "cs", k = 4), data = out)
      plot(gam_model)
      # -- Use in-place correction on data_original
      #    This avoids creating a separate temporary data.table.
      data_original[, predicted_drift_ppm :=
                      predict(gam_model, newdata = .SD),
                    .SDcols = "m.z"]
      data_original[, m.z :=
                      m.z * (1 + predicted_drift_ppm / 1e6)]
      # Optionally remove the predicted_drift_ppm column
      
    } else {
    }
    

    if(showplot & nrow(out) > 20){
      plot1 <- plot_ly() %>%
        
        add_trace(data = out, x = ~m.z, y = ~ppm, type = 'scatter', mode = 'markers',
                  marker = list(color = 'grey', size = 5), name = paste0("SSE before: ",SSE_1)) %>%
        add_trace(data = data_original, x = ~m.z, y = ~predicted_drift_ppm, type = 'scatter', mode = 'lines',
                  line = list(color = 'red', width = 2), name = 'GAM Model') %>%
        layout(title = samplename, xaxis = list(title = "m/z", range=c(min(out$m.z),max(out$m.z))),
               yaxis = list(title = "ppm", range=c(-ppm_tolerance,ppm_tolerance)))
      
      #repeat assignment
      data <- data_original[I / MDL > S_MDL_limit]
      
      # 3) Assign formulas and filter by atomic composition
      out <- formula_assignment_multi_intensity(
        formulas,
        data,
        ppm_tolerance = ppm_tolerance,
        ion           = ion,
        threshold = 200,
        delete_singlets = F,
        delete_MF_without_connection = F
      )
      out[, homologues_membership := NULL]
      
      
      out <- calculate_connections(out)[homologues_membership >= hom_member_min]
      
      
      # -- Quantile-based filtering in data.table style
      Q1   <- quantile(out$ppm, 0.25)
      Q3   <- quantile(out$ppm, 0.75)
      IQRv <- Q3 - Q1
      out  <- out[ppm > (Q1 - 1.5 * IQRv) & ppm < (Q3 + 1.5 * IQRv)]
      SSE_2 <- round(sum(out$ppm^2),2)
      
      plot2 <- plot_ly() %>%
        
        add_trace(data = out, x = ~m.z, y = ~ppm, type = 'scatter', mode = 'markers',
                  marker = list(color = 'black', size = 5), name = paste0("SSE after: ",SSE_2)) %>%
        
        layout(title = samplename, xaxis = list(title = "m/z", range=c(min(out$m.z),max(out$m.z))), yaxis = list(title = "ppm"))
      
      
      plot <- subplot(plot1, plot2, shareY = T, titleX = T, titleY = T)
      
      
    }
    gc()
    
    }, error = function(e) {
    print(paste0("Error in Sample: ",samplename, ". Original data returned"))
  })

  return(list(data =data_original[, .(m.z, I, MDL)],
              plot = plot,
              SSE_1 = SSE_1,
              SSE_2 = SSE_2))
}

# -- Panel 3 UI --
panel3_ui <- fluidPage(
  titlePanel("MZ Recalibration Tool"),
  sidebarLayout(
    sidebarPanel(
      numericInput("ppm_tolerance", "ppm tolerance:", value = 0.5, min = 0, step = 0.05),
      numericInput("S_MDL_limit", "S/MDL lower limit:", value = 2, min = 0, step = 0.1),
      numericInput("hom_member_min", "Homologue network length min:", value = 2, min = 1, step = 1),
      actionButton("calculate_mz", "Recalibrate", class = "btn-lg btn-success"),
      downloadButton("download_recalibrated", "Download as .rds")  ,
      uiOutput("sample_slider_ui")
    ),
    mainPanel(
      tabsetPanel(
        tabPanel(
          "Plot", 
          fluidRow(
            plotlyOutput("extra_plot"), # Extra plot above the main plot
            plotlyOutput("mz_plot")    # Main m/z plot
          )
        )
      )
    )
  )
)

# -- Panel 3 Server --
panel3_server <- function(input, output, session) {
  
  recal_data <- reactiveVal(NULL)
  
  observeEvent(input$calculate_mz, {
    if (!exists("samples_MDL", envir = .GlobalEnv)) {
      showNotification("Error: 'samples_MDL' not found in global environment.", type = "error")
      return(NULL)
    }
    
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    local_samples <- get("samples_MDL", envir = .GlobalEnv)
    #local_formulas <- get("molecular_formulas", envir = .GlobalEnv)
    
    progress <- Progress$new(session, min = 0, max = length(local_samples))
    on.exit(progress$close())
    
    #formulas for calibration: more conservative range
    formulas_calibration <- generate_formulas(C_range = 2:50, H_range = 2:100, O_range = 1:20,
                                              P_range = 0:0, N_range = 0:1, S_range = 0:1,
                                              HC= c(1,2), OC = c(0.2,0.8), mass_range = c(100, 1000), insert_isotopes = T)
    sample_names <- names(local_samples)
    out_list <- lapply(seq_along(local_samples), function(i) {
      progress$set(value = i, message = "Processing samples", detail = paste0("Sample ", i, " of ", length(local_samples)))
      
      mz_recalibration(formulas_calibration, local_samples[[i]],
                       ppm_tolerance = input$ppm_tolerance,
                       S_MDL_limit = input$S_MDL_limit,
                       hom_member_min = input$hom_member_min,
                       showplot = TRUE, samplename = sample_names[i])
    })
    recal_data(out_list)
    out_data <- lapply(out_list, function(x){x$data})
    names(out_data) <- names(samples_MDL)
    
    #assign("samples_MDL_recal_data", lapply(out_list, `[[`, "data"), envir = .GlobalEnv)
    assign("samples_MDL_recal_data", out_data, envir = .GlobalEnv)
    
    removeNotification(notification_id)
    showNotification("MZ Recalibration complete! 'samples_MDL_recal_data' saved globally.", type = "message")
    
    output$download_recalibrated <- downloadHandler(
      filename = function() {
        paste("Recalibrated_samples", Sys.Date(), ".rds", sep = "")
      },
      content = function(file) {
        saveRDS(out_data, file)
      }
    )
  })
  
  output$sample_slider_ui <- renderUI({
    req(recal_data())
    sliderInput(
      "sample_slider",
      "Select Sample:",
      min = 1,
      max = length(recal_data()),
      value = 1,
      step = 1
    )
  })
  
  current_sample <- reactiveVal(1)
  
  observeEvent(input$sample_slider, {
    req(recal_data())
    current_sample(input$sample_slider)
  })
  
  output$mz_plot <- renderPlotly({
    req(recal_data())
    idx <- current_sample()
    if (idx > 0 && idx <= length(recal_data())) {
      recal_data()[[idx]]$plot
    }
  })
  
  # Generate the extra plot, unaffected by slider
  output$extra_plot <- renderPlotly({
    req(recal_data())
    SSE_1 <- sapply(recal_data(), function(x) x$SSE_1)
    SSE_2 <- sapply(recal_data(), function(x) x$SSE_2)
    x <-seq_along(SSE_1)
    plot_ly(
      x = x,
      y = SSE_1,
      type = "scatter",
      mode = "markers",
      name = "SSE before"
    ) %>%   add_trace(    x = x,
    y = SSE_2,
    type = "scatter",
    mode = "markers",
    name = "SSE after"
  ) %>%  layout(title = "SSE before/after",
                xaxis = list(title = "Sample Index"),
                yaxis = list(title = "SSE"))
  })
}


###############################################################################
#               Panel 4:  Functions & Shiny UI/Server Code                    #
#                      (Merge m/z Values)                                     #
###############################################################################

# -- Panel 4 Functions --
merge_mz_values <- function(dt, ppm_tolerance) {
  
  
  # # Rename columns 
  # setnames(dt, old = colnames(dt)[1], new = "mz")
  # setnames(dt, old = colnames(dt)[3], new = "MDL")
  
  # Sort by m/z
  
  setorder(dt, m.z)
  
  # Compute difference in ppm between consecutive m/z
  dt[, diff_ppm := (m.z - shift(m.z, type = "lag")) / shift(m.z, type = "lag") * 1e6]
  # Replace the first NA with Inf (equivalent to c(Inf, diff(m.z))/m.z * 1e6)
  dt[is.na(diff_ppm), diff_ppm := Inf]
  
  # Identify groups whose differences exceed ppm_tolerance
  dt[, group := cumsum(diff_ppm > ppm_tolerance)]
  
  # Calculate the weighted mean m/z and other values 
  merged <- dt[, {
    sqrt_I <- sqrt(I)
    sum_sqrt_I <- sum(sqrt_I)
    .(
      merged_m.z = sum(m.z * sqrt_I) / sum_sqrt_I,
      mean_MDL  = MDL[1],            #MDL should be the same accross all samples.                   
      SE        = sd(m.z) / (sum(m.z * sqrt_I) / sum_sqrt_I) * 1e6
    )
  }, by = group]
  
  # Update-join  to add columns back
  dt[merged, on = "group", `:=`(
    merged_m.z = i.merged_m.z,
    mean_MDL  = i.mean_MDL,
    SE        = i.SE
  )]
  
  # Remove duplicates by selecting the first row per group and index
  dt2 <- dt[, .SD[1], keyby = .(group, index)]
  
  # Reshape to wide format; each index becomes a column
  dt_wide <- dcast(
    dt2,
    merged_m.z + mean_MDL + SE ~ index,
    value.var = "I",
    fill = NA
  )
  
  # Rename columns for the final output
  setnames(dt_wide, old = c("merged_m.z", "mean_MDL"), new = c("m.z", "MDL"))
  gc()
  return(dt_wide)
}


# -- Panel 4 UI --
panel4_ui <- fluidPage(
  titlePanel("Merge m/z Values"),
  sidebarLayout(
    sidebarPanel(
      numericInput("ppm_tolerance_merge", "PPM Tolerance:", value = 0.5, min = 0, step = 0.1),
      actionButton("calculate_merge", "Merge samples", class = "btn-lg btn-success"),
      downloadButton("download_csv_merged", "Download CSV")  
    ),
    mainPanel(
      verbatimTextOutput("status_merge"),
      DTOutput("results_table_merge")
    )
  )
)

# -- Panel 4 Server --
panel4_server <- function(input, output, session) {
  
  observeEvent(input$calculate_merge, {
    # Ensure samples_MDL_recal_data exists
    if (!exists("samples_MDL_recal_data", envir = .GlobalEnv)) {
      output$status_merge <- renderText("Error: 'samples_MDL_recal_data' is not found in the global environment.")
      return(NULL)
    }
    
    # Perform the calculation
    output$status_merge <- renderText("Calculating...")
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    
    tryCatch({
      local_samples <- get("samples_MDL_recal_data", envir = .GlobalEnv)
      combined_dt <- rbindlist(local_samples, fill = TRUE, idcol = "index")
      result_dt <- merge_mz_values(combined_dt, ppm_tolerance = input$ppm_tolerance_merge)
      
      # Assign result to global environment
      assign("merged_samples", result_dt, envir = .GlobalEnv)
      removeNotification(notification_id)
      output$status_merge <- renderText("Calculation complete! Check the global environment for 'merged_samples'. Table below shows the header.")
    }, error = function(e) {
      output$status_merge <- renderText(paste("Error:", e$message))
    })
    output$results_table_merge <- renderDT({
      head(result_dt)
    })
    output$download_csv_merged <- downloadHandler(
      filename = function() {
        paste("Merged_samples", Sys.Date(), ".csv", sep = "")
      },
      content = function(file) {
        fwrite(result_dt, file)
      }
    )
    
  })
}

###############################################################################
#               Panel 5:  Functions & Shiny UI/Server Code                    #
#              (Formula Assignment and Isotope Calculation)                   #
###############################################################################

# -- Panel 5 Functions --
# Compute isotope deviance
isotope_deviance <- function(intensity_parent, intensity_child,
                             number_of_atoms, q, p, number_of_isotopes = 1) {
  expected_intensity_ratio <- dbinom(number_of_isotopes, number_of_atoms, q) /
    dbinom(number_of_atoms, number_of_atoms, p)
  ratio <- intensity_child / intensity_parent
  
  # Weighted mean of ratio, then scaled relative to expected_intensity_ratio
  rdeviance_weighted <- ((weighted.mean(ratio, intensity_parent, na.rm = TRUE) /
                            expected_intensity_ratio) - 1) * 1000
  return(round(rdeviance_weighted))
}

# Compute a formula string from element counts
construct_formula <- function(elements) {
  # e.g., elements = list(C=6, H=12, O=6, ...)
  # each gets turned into "C6", "H12", etc., omitting the number if == 1
  formula_parts <- paste0(names(elements),
                          ifelse(elements == 1, "", elements))
  formula <- paste(formula_parts[elements > 0], collapse = "")
  return(formula)
}

# Identify group connections for a single group
calculate_group_connections <- function(dt_group, diffs) {
  group_results <- list()
  
  # For each type of difference (CH2, H, etc.) 
  for (diff_name in names(diffs)) {
    diff_vector <- diffs[[diff_name]]
    diff_dt <- dt_group[, .(
      C = C + diff_vector["C"],
      H = H + diff_vector["H"],
      O = O + diff_vector["O"],
      N = N + diff_vector["N"],
      S = S + diff_vector["S"],
      P = P + diff_vector["P"],
      from_index = index
    )]
    
    # Match the diff_dt to dt_group by the new formula
    setkeyv(diff_dt, c("C", "H", "O", "N", "S", "P"))
    setkeyv(dt_group, c("C", "H", "O", "N", "S", "P"))
    
    #the following can throw an error if allow.cartesian is not set to true.
    #need to investigate the reason.
    matched <- dt_group[diff_dt, nomatch = 0L, allow.cartesian = TRUE]
    
    if (nrow(matched) > 0) {
      group_results[[diff_name]] <- matched[, .(
        from_index = from_index,
        to_index = index,
        connection_type = diff_name
      )]
    }
  }
  
  # Combine all connections for this group
  all_group_connections <- data.table::rbindlist(group_results, use.names = TRUE, fill = TRUE)
  
  # Tag any formula with no connections
  no_connections <- dt_group[
    !index %in% unique(c(all_group_connections$from_index, all_group_connections$to_index)),
    .(from_index = index, to_index = NA, connection_type = "No Connection")
  ]
  all_group_connections <- rbind(all_group_connections, no_connections, fill = TRUE)
  
  return(all_group_connections)
}

# --- Main Functions ---

# Main function: calculate isotopes
calculate_isotopes <- function(filtered_matches, dataset) {
  
  # Identify intensity columns
  intensity_cols <- setdiff(
    names(dataset),
    c("m.z", "MDL", "SE", "m.z_ion", "index")
  )
  
  # Compute combined intensities (rowMeans if >1 column, or single column)
  if (length(intensity_cols) > 1) {
    intensities <- dataset[, .(m.z, intensities = rowMeans(.SD, na.rm = TRUE)),
                           .SDcols = intensity_cols]
  } else {
    intensities <- dataset[, .(m.z, intensities = get(intensity_cols))]
  }
  
  # Merge intensities into filtered_matches
  filtered_matches <- merge(filtered_matches, intensities,
                            by.x = "m.z", by.y = "m.z", all.x = TRUE)
  
  # Split into parent vs. child isotopes
  parent_all    <- filtered_matches[C_13 == 0 & O_18 == 0 & S_34 == 0]
  child_C_1_all <- filtered_matches[C_13 == 1 & O_18 == 0 & S_34 == 0]
  child_C_2_all <- filtered_matches[C_13 == 2 & O_18 == 0 & S_34 == 0]
  child_O_all   <- filtered_matches[C_13 == 0 & O_18 == 1 & S_34 == 0]
  child_S_all   <- filtered_matches[C_13 == 0 & O_18 == 0 & S_34 == 1]
  
  # Merge parent and child sets
  result_C1 <- merge(
    parent_all, child_C_1_all,
    by = c("C", "H", "O", "N", "S", "P"),
    suffixes = c("_parent", "_child")
  )
  result_C2 <- merge(
    parent_all, child_C_2_all,
    by = c("C", "H", "O", "N", "S", "P"),
    suffixes = c("_parent", "_child")
  )
  result_O <- merge(
    parent_all, child_O_all,
    by = c("C", "H", "O", "N", "S", "P"),
    suffixes = c("_parent", "_child")
  )
  result_S <- merge(
    parent_all, child_S_all,
    by = c("C", "H", "O", "N", "S", "P"),
    suffixes = c("_parent", "_child")
  )
  
  # Filter out lines where parent intensity <= child intensity
  result_C1 <- result_C1[intensities_parent > intensities_child]
  result_C2 <- result_C2[intensities_parent > intensities_child]
  result_O  <- result_O[intensities_parent > intensities_child]
  result_S  <- result_S[intensities_parent > intensities_child]
  
  # Calculate isotope deviance in each group, row by row
  col_parent <- "intensities_parent"
  col_child  <- "intensities_child"
  
  result_C1[, isotope_deviance_C_13_1 := isotope_deviance(
    as.numeric(get(col_parent)),
    as.numeric(get(col_child)),
    number_of_atoms = C,
    q = 0.0108,
    p = 1 - 0.0108,
    number_of_isotopes = 1
  ), by = seq_len(nrow(result_C1))]
  
  result_C2[, isotope_deviance_C_13_2 := isotope_deviance(
    as.numeric(get(col_parent)),
    as.numeric(get(col_child)),
    number_of_atoms = C,
    q = 0.0108,
    p = 1 - 0.0108,
    number_of_isotopes = 2
  ), by = seq_len(nrow(result_C2))]
  
  result_O[, isotope_deviance_O_18 := isotope_deviance(
    as.numeric(get(col_parent)),
    as.numeric(get(col_child)),
    number_of_atoms = O,
    q = 0.00205,
    p = 1 - 0.00205,
    number_of_isotopes = 1
  ), by = seq_len(nrow(result_O))]
  
  result_S[, isotope_deviance_S_34 := isotope_deviance(
    as.numeric(get(col_parent)),
    as.numeric(get(col_child)),
    number_of_atoms = S,
    q = 0.0437,
    p = 1 - 0.0437,
    number_of_isotopes = 1
  ), by = seq_len(nrow(result_S))]
  
  
  # 1) Identify columns with '_parent' or '_child'
  #    (we do this once; assume each "result_X" has consistent column naming)
  parent_cols <- grep("_parent$", names(result_C1), value = TRUE)
  child_cols  <- grep("_child$",  names(result_C1), value = TRUE)
  
  # 2) Common columns in your data
  common_cols <- c("C", "H", "O", "N", "S", "P")
  
  # 3) For each merged result (C1, C2, O, S), create a 'parent' table and 'child' table
  #    removing the 'intensities' column in each subset to avoid duplication.
  #    Then rename columns to remove _parent and _child suffixes for clarity.
  split_and_rename <- function(dt, iso_col) {
    dt_parent <- dt[, c(common_cols, parent_cols, iso_col), with = FALSE]
    dt_child  <- dt[, c(common_cols, child_cols,  iso_col), with = FALSE]
    
    setnames(dt_parent, gsub("_parent$", "", names(dt_parent)))
    setnames(dt_child,  gsub("_child$",  "", names(dt_child)))
    
    # Remove 'intensities' column in each subset if present
    if ("intensities" %in% names(dt_parent)) dt_parent[, intensities := NULL]
    if ("intensities" %in% names(dt_child))  dt_child[, intensities := NULL]
    
    return(list(parent = dt_parent, child = dt_child))
  }
  
  pc_C1 <- split_and_rename(result_C1, "isotope_deviance_C_13_1")
  pc_C2 <- split_and_rename(result_C2, "isotope_deviance_C_13_2")
  pc_O  <- split_and_rename(result_O,  "isotope_deviance_O_18")
  pc_S  <- split_and_rename(result_S,  "isotope_deviance_S_34")
  
  
  by_child <- names(pc_C1$child)[-ncol(pc_C1$child)]
  
  isotopes <- merge(pc_C1$child, pc_C2$child, by = by_child, all = TRUE)
  isotopes <- merge(isotopes, pc_O$child, by = by_child, all = TRUE)
  isotopes <- merge(isotopes, pc_S$child, by = by_child, all = TRUE)
  
  
  if ("intensities" %in% names(parent_all)) {
    parent_all[, intensities := NULL]
  }
  
  # Combine 'parent_all' with all isotopes
  gc()
  return(rbind(parent_all, isotopes, fill = TRUE))
}

# Calculate homologous connections (panel 5)
calculate_connections <- function(dt, diffs = list(
  CH2 = c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0),
  H   = c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
)) {
  data.table::setorder(dt, C, H, O)
  dt[, index := .I]
  
  # Group assignment
  dt[, group := fifelse(N > 0 & P > 0, "NP",
                        fifelse(N > 0 & (S > 0 | S_34 > 0), "NS",
                                fifelse((S > 0 | S_34 > 0) & P > 0, "SP",
                                        fifelse(N > 0 & S == 0 & P == 0 & S_34 == 0, "N",
                                                fifelse((S > 0 | S_34 > 0) & N == 0 & P == 0, "S",
                                                        fifelse(P > 0 & S == 0 & N == 0 & S_34 == 0, "P",
                                                                fifelse(O > 0 & P == 0 & S == 0 & N == 0 & S_34 == 0, "CHO",
                                                                        fifelse(O == 0 & P == 0 & S == 0 & N == 0 & S_34 == 0, "CH", "None"))))))))]
  
  # Calculate connections in each group
  results <- list()
  for (grp in unique(dt$group)) {
    dt_group <- dt[group == grp]
    grp_con <- calculate_group_connections(dt_group, diffs)
    results[[grp]] <- grp_con
  }
  
  # Combine all group connections
  all_connections <- data.table::rbindlist(results, use.names = TRUE, fill = TRUE)
  
  # Graph-based approach to membership
  Ak <- igraph::graph_from_data_frame(all_connections[!is.na(to_index)], directed = FALSE) %>%
    igraph::components()
  membership_dt <- data.table::data.table(index = as.integer(names(Ak$membership)),
                                          homologues_membership = Ak$membership)
  membership_dt[, homologues_membership := .N, by = homologues_membership]
  
  out <- merge(dt, membership_dt, by = "index", all.x = TRUE)
  out[is.na(homologues_membership), homologues_membership := 1]
  
  # We typically don't need explicit garbage collection calls repeatedly
  return(out)
}

# Main formula assignment that calls the above functions
formula_assignment_multi_intensity <- function(
    formulas, dataset, ppm_tolerance = 0.5,
    ion = 1.007825032 + -1 * 0.00054857990907,
    threshold = 1000, return_likeliest = TRUE,
    delete_singlets = TRUE, delete_MF_without_connection = TRUE,
    homologues_network = list(
      CH2 = c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0),
      H   = c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
    )
) {
  dat <- copy(dataset) #create a clean copy to remove referencing to old dataset

  # Adjust m.z by the chosen ion mass
  dat[, m.z_ion := m.z]
  dat[, m.z := m.z + ion]
  
  # Generate tolerance columns
  dat[, `:=`(lower_limit = m.z * (1 - ppm_tolerance / 1e6),
                 upper_limit = m.z * (1 + ppm_tolerance / 1e6))]

  # Prepare formula data and set keys for overlap
  formulas[, `:=`(start = calculated_m.z, end = calculated_m.z)]
  data.table::setkey(formulas, start, end)
  data.table::setkey(dat, lower_limit, upper_limit)
  
  all_matches <- data.table()
  # Overlap join
  all_matches <- foverlaps(
    formulas, dat, 
    by.x = c("start", "end"),
    by.y = c("lower_limit", "upper_limit"),
    type = "within", nomatch = 0
  )
  dat[, `:=`(lower_limit = NULL, upper_limit = NULL)]
  
  # Calculate error & filter columns
  all_matches[, absolute_error := calculated_m.z - m.z]
  all_matches[, ppm := (absolute_error / m.z) * 1e6]
  
  filtered_matches <- data.table()
  filtered_matches <- all_matches[, .(
    m.z_ion, m.z, calculated_m.z, absolute_error, ppm,
    C, H, O, N, S, P, C_13, O_18, S_34
  )]
  
  all_matches <- NULL
  # 1) Isotope peak verification
  #automatically removes peaks where the main isotope intensity is below isotope peak intensity
  filtered_matches <- calculate_isotopes(filtered_matches, dat = dat)
  
  # 2) Homologous series calculation
  filtered_matches <- calculate_connections(filtered_matches, diffs = homologues_network)
  filtered_matches[, index := NULL]
  
  # Threshold test
  filtered_matches[, isotope_below_threshold := (
    isotope_deviance_C_13_1 < threshold |
      isotope_deviance_C_13_2 < threshold |
      isotope_deviance_O_18   < threshold |
      isotope_deviance_S_34   < threshold
  )]
  
  # Return only best match per measured m/z if requested
  if (return_likeliest) {
    filtered_matches[, abs_ppm := abs(ppm)]
    data.table::setorder(filtered_matches, m.z, -isotope_below_threshold,
                         -homologues_membership, abs_ppm)
    filtered_matches <- filtered_matches[, .SD[1], by = m.z]
    filtered_matches[, c("abs_ppm", "homologues_membership") := NULL]
    
    # Keep only isotopes with deviance below threshold
    filtered_matches <- subset(filtered_matches,
                               (C_13 == 0 | isotope_below_threshold == TRUE) &
                                 (O_18 == 0 | isotope_below_threshold == TRUE) &
                                 (S_34 == 0 | isotope_below_threshold == TRUE)
    )
    
    # Recompute connections
    filtered_matches <- calculate_connections(
      filtered_matches, diffs = homologues_network
    )
  }
  
  # 3) Construct molecular formula and compute other metrics
  filtered_matches[, MF := construct_formula(
    list(C = C, H = H, O = O, N = N, S = S, P = P)
  ), by = 1:nrow(filtered_matches)]
  
  filtered_matches[, AI_mod := (1 + C - 0.5 * O - S - 0.5 * (H + N + P)) /
                     (C - 0.5 * O - S - N - P)]
  filtered_matches[, AI_mod := ifelse(AI_mod < 0 | is.infinite(AI_mod), 0, AI_mod)]
  filtered_matches <- filtered_matches[AI_mod <= 1]
  
  filtered_matches[, NOSC := (-(4*C + H - 3*N - 2*O + 5*P - 2*S) / C) + 4]
  filtered_matches[, `:=`(
    O.C = O/C, H.C = H/C, N.C = N/C, S.C = S/C, P.C = P/C
  )]
  
  # Simple classification
  filtered_matches[, class := fifelse(
    O.C > 0 & O.C <= 0.3 & H.C > 1.5 & H.C <= 2.5, "Lipid",
    fifelse(
      O.C <= 0.125 & H.C >= 1 & H.C <= 1.5 & AI_mod > 0.5, "Unsaturated hydrocarbon",
      fifelse(
        O.C > 0.3 & O.C <= 0.55 & H.C > 1.5 & H.C <= 2.3, "Protein",
        fifelse(
          O.C > 0.55 & O.C <= 0.7 & H.C > 1.5 & H.C <= 2.2, "Aminosugar",
          fifelse(
            O.C > 0.7 & O.C <= 1.05 & H.C > 1.5 & H.C <= 2.2, "Carbohydrate",
            fifelse(
              AI_mod >= 0.67, "Condensed hydrocarbon",
              fifelse(
                AI_mod < 0.67 & AI_mod > 0.5 & O.C > 0.125, "Aromatic",
                fifelse(
                  O.C > 0.125 & AI_mod <= 0.5 & H.C <= 1.5,
                  "Highly unsaturated", "Unassigned"
                )
              )
            )
          )
        )
      )
    )
  )]
  
  # Reorder/filter columns
  filter_cols <- c(
    "m.z_ion", "m.z", "calculated_m.z", "absolute_error", "ppm", "MF",
    "group", "class", "C", "H", "O", "N", "S", "P", "C_13", "O_18", "S_34",
    "H.C", "O.C", "N.C", "S.C", "P.C", "AI_mod", "NOSC", "homologues_membership",
    "isotope_deviance_C_13_1", "isotope_deviance_C_13_2",
    "isotope_deviance_O_18", "isotope_deviance_S_34", "isotope_below_threshold"
  )
  filtered_matches <- filtered_matches[, ..filter_cols]
  
  # Merge original dat columns back in and track presence
  dat[, m.z := NULL]
  filtered_matches <- merge(filtered_matches, dat, 
                            by.x = "m.z_ion", by.y = "m.z_ion", all.x = TRUE)

  selected_cols <- setdiff(names(filtered_matches), filter_cols) # Remove filter_cols
  selected_cols <- selected_cols[!grepl("SE|MDL|predicted_drift_ppm", selected_cols)] # Exclude columns containing "SE" or "MDL"
  

  filtered_matches[, present_in := rowSums(!is.na(.SD)), .SDcols = selected_cols]

  
  # Move `present_in` column to just after the filter_cols
  filter_col_names <- c(names(filtered_matches)[1:length(filter_cols)], "present_in", "MDL")
  setcolorder(filtered_matches, c(filter_col_names,setdiff(names(filtered_matches),
                                                                    c(filter_col_names))))

  
  # Delete singlets if chosen
  if (delete_singlets) {
    filtered_matches <- subset(filtered_matches, present_in > 1)
  }
  
  # Possibly delete MF without a homologous connection
  if (delete_MF_without_connection) {
    # Recalculate homologues membership after removing singlets
    if (delete_singlets) {
      temp <- copy(filtered_matches)
      temp[, homologues_membership := NULL]
      filtered_matches$homologues_membership <- calculate_connections(
        temp, diffs = homologues_network
      )$homologues_membership
    }
    filtered_matches <- subset(filtered_matches, homologues_membership > 1)
    temp <- NULL
  }
  
  setorder(filtered_matches, m.z)
  dat <- NULL
  formulas[, start := NULL]
  formulas[, end := NULL]
  
  
  gc()
  return(filtered_matches)
}


# -- Panel 5 UI --
panel5_ui <- fluidPage(
  titlePanel("Formula Assignment and Isotope Calculation"),
  sidebarLayout(
    sidebarPanel(
      numericInput("ppm_tolerance_panel5", "ppm tolerance:", value = 0.3, min = 0, step = 0.1),
      numericInput("threshold_panel5", "Isotope deviance threshold:", value = 1000, min = 0, step = 1),
      checkboxInput("return_likeliest_panel5", "Return Likeliest", value = TRUE),
      checkboxInput("delete_singlets", "Delete Singlets", value = TRUE),
      checkboxInput("delete_MF_without_connection", "Delete MF without Connection", value = TRUE),
      checkboxGroupInput("homologues_network_panel5", "Select Homologues Network:", 
                         choices = list(
                           "CH2"  = "CH2",
                           "CH2O" = "CH2O",
                           "C2HO" = "C2HO",
                           "CO2"  = "CO2",
                           "H2O"  = "H2O",
                           "H"    = "H",
                           "O"    = "O",
                           "NH3"  = "NH3"
                         ),
                         selected = c("CH2",  "O")),
      actionButton("calculate_panel5", "Assign Formulas", class = "btn-lg btn-success"),
      downloadButton("download_csv_crosstab", "Download CSV") ,
      textOutput("status_panel5")
    ),
    mainPanel(
      DTOutput("results_table_panel_5")
    )
  )
)

# -- Panel 5 Server --
panel5_server <- function(input, output, session) {
  
  crosstab <- reactiveVal(NULL)
  
  observeEvent(input$calculate_panel5, {
    output$status_panel5 <- renderText("Calculating...")
    
    # Ensure we have 'formulas' and 'merged_samples' in global environment
    if (!exists("molecular_formulas", envir = .GlobalEnv)) {
      output$status_panel5 <- renderText("Error: 'formulas' is not found in the global environment.")
      return(NULL)
    }
    if (!exists("merged_samples", envir = .GlobalEnv)) {
      output$status_panel5 <- renderText("Error: 'merged_samples' is not found in the global environment.")
      return(NULL)
    }
    
    local_formulas <- get("molecular_formulas", envir = .GlobalEnv)
    local_water_dt <- get("merged_samples", envir = .GlobalEnv)
    
    tryCatch({
      selected_homologues <- list()
      if ("CH2"  %in% input$homologues_network_panel5) selected_homologues$CH2  <- c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0)
      if ("CH2O" %in% input$homologues_network_panel5) selected_homologues$CH2O <- c(C = 1, H = 2, O = 1, N = 0, S = 0, P = 0)
      if ("C2HO" %in% input$homologues_network_panel5) selected_homologues$C2HO <- c(C = 2, H = 1, O = 1, N = 0, S = 0, P = 0)
      if ("CO2"  %in% input$homologues_network_panel5) selected_homologues$CO2  <- c(C = 1, H = 0, O = 2, N = 0, S = 0, P = 0)
      if ("H2O"  %in% input$homologues_network_panel5) selected_homologues$H2O  <- c(C = 0, H = 2, O = 1, N = 0, S = 0, P = 0)
      if ("H"    %in% input$homologues_network_panel5) selected_homologues$H    <- c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
      if ("O"    %in% input$homologues_network_panel5) selected_homologues$O    <- c(C = 0, H = 0, O = 1, N = 0, S = 0, P = 0)
      if ("NH3"  %in% input$homologues_network_panel5) selected_homologues$NH3  <- c(C = 0, H = 3, O = 0, N = 1, S = 0, P = 0)
      
      notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
      
      result <- formula_assignment_multi_intensity(
        formulas          = local_formulas,
        dataset           = local_water_dt,
        ppm_tolerance     = input$ppm_tolerance_panel5,
        threshold         = input$threshold_panel5,
        return_likeliest  = input$return_likeliest_panel5,
        homologues_network= selected_homologues,
        delete_singlets   = input$delete_singlets,
        delete_MF_without_connection = input$delete_MF_without_connection
      )
      
      crosstab(result)
      
      assign("crosstab", result, envir = .GlobalEnv)
      output$status_panel5 <- renderText("Calculation complete. Results saved to 'crosstab' in your R environment.")
      removeNotification(notification_id)
      
      output$download_csv_crosstab <- downloadHandler(
        filename = function() {
          paste("crosstab", Sys.Date(), ".csv", sep = "")
        },
        content = function(file) {
          fwrite(result, file)
        }
      )
      
    }, error = function(e) {
      output$status_panel5 <- renderText(paste("Error:", e$message))
    })
  })
  
  output$results_table_panel_5 <- renderDT({
    crosstab()
  })
  
  
}


###############################################################################
#                             COMBINED UI & SERVER                             #
###############################################################################

# Combine all panel UIs into one "navbarPage".
# Then define one server that calls each panelâs server function within its own scope.

ui <- navbarPage(
  title = "Formula Assigner",
  
  tabPanel(
    "MDL",
    panel1_ui
  ),
  
  tabPanel(
    "Formula Template",
    panel2_ui
  ),
  
  tabPanel(
    "Recalibration",
    panel3_ui
  ),
  
  tabPanel(
    "Sample Merging",
    panel4_ui
  ),
  
  tabPanel(
    "Formula Assignment",
    panel5_ui
  )
)

# A single server function that calls each panel's server logic
server <- function(input, output, session) {
  callModule(module = panel1_server, id = NULL)
  callModule(module = panel2_server, id = NULL)
  callModule(module = panel3_server, id = NULL)
  callModule(module = panel4_server, id = NULL)
  callModule(module = panel5_server, id = NULL)
  
  session$onSessionEnded(function() {
    stopApp()
  })
}

# Launch the unified Shiny app
shinyApp(ui, server)


# 
# #data processing
# sub <- crosstab
# #sub[, present_in := rowSums(!is.na(.SD)), .SDcols = 33:77]
# sub[, present_in_percent := (present_in / 45) * 100]
# sub1 <- subset(sub, sub$homologues_membership >4 & sub$present_in >1)
# #sub1 <- subset(sub1, sub1$`masslistsESI_neg_Nelha_25ppm_200scans_0-1acc_mid_20200812_000001` >0)
# plot <- vk_plot_hist(list(sub1))#, sizes = list(sqrt(sub1$present_in_percent)))
# plot
# 
# plot_mass_spectrum(dat = list(as.data.frame(sub1)), intensity_colum = 33, norm = F)



#reduce overhead: button to remove original files after mdl calculation?
#rewrite recalibration function to not use lapply and instead only data.table syntax.
#try to remove lapply where possible to remove overhead
