###############################################################################
#This provides a graphical user interface to perform all calculations. 
#Results from each step are being exported into the local R environment.
#
# Work in progress. No diagnostic plots and less options compared to running the functions individually
###############################################################################
library(bit64)
library(shiny)
library(data.table)
library(quantreg)
library(dplyr)
library(DT)
library(plotly)
library(mgcv)
library(igraph)

###############################################################################
#               Panel 1:  Functions & Shiny UI/Server Code                    #
#                    (Instrument Blanks Noise Removal)                    #
###############################################################################

# -- Panel 1 Functions --
# Set maximum file size (adjust as needed)
options(shiny.maxRequestSize = 4096 * 4096 * 4096)

# Function to remove outliers in ResPow based on quantile regression
ResPow_outlier <- function(dataset) {
  
  # Fit quantile regression model
  d <- rq(log(ResPow) ~ log(m.z), data = dataset, method = "fn")
  
  # Density of residuals
  dens <- density(d$residuals)
  
  # Identify threshold e in a single chained operation:
  e <- data.table(x = dens$x[-1], y = diff(dens$y))[
    x > 0
  ][
    which.min(y):.N
  ][
    y > 0, x[1]
  ]
  
  # If no threshold is found, use Inf
  if (is.na(e)) e <- Inf
  
  # Return only rows whose residuals are within ±e
  dataset[d$residuals <= abs(e)]
}

# Function to process samples and remove peaks below MDL
process_samples_MDL <- function(sample, sample_name, MDL_master) {
  #0. change integer 64 into numeric for intensity
  sample[, I := round(as.numeric(I), -4)]
  
  # 1. Rename columns in place
  setnames(sample, old = "m/z", new = "m.z", skip_absent = TRUE)
  
  # 2. Calculate nominal_mz
  sample[, nominal_mz := floor(m.z + 0.5)]
  
  # 3. Merge, then filter to keep only rows above MDL, 
  #    and pick the necessary columns in a single step.
  # 4. Immediately pass the result to ResPow_outlier() to remove outliers.
  merge(
    sample, MDL_master, by.x = "nominal_mz", by.y = "m.z", all.x = TRUE
  )[
    I >= MDL,
    .(m.z, I, MDL, ResPow = Res., index = sample_name)
  ] |>
    ResPow_outlier()
}

# -- Panel 1 UI --
panel1_ui <- fluidPage(
  titlePanel("Instrument Blanks Noise Removal"),
  
  sidebarLayout(
    sidebarPanel(
      fileInput("blanks_files", "Select Instrument blank file(s):", 
                multiple = TRUE, accept = c(".csv")),
      fileInput("samples_files", "Select sample files:", 
                multiple = TRUE, accept = c(".csv")),
      numericInput("confidence_level", "Confidence Level:", value = 0.998, min = 0, max = 1, step = 0.001),
      actionButton("calculate", "Calculate")
    ),
    
    mainPanel(
      verbatimTextOutput("status"),
      tableOutput("overview")
    )
  )
)

# -- Panel 1 Server --
panel1_server <- function(input, output, session) {
  
  blanks_data <- reactive({
    req(input$blanks_files)
    lapply(input$blanks_files$datapath, fread)
  })
  
  samples_data <- reactive({
    req(input$samples_files)
    samples <- lapply(input$samples_files$datapath, fread)
    names(samples) <- tools::file_path_sans_ext(basename(input$samples_files$name))
    samples
  })
  
  samples_MDL <- eventReactive(input$calculate, {
    req(blanks_data(), samples_data())
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    blank_list <- blanks_data()
    sample_list <- samples_data()
    
    # Compute MDL_master
    MDL_master <- lapply(blank_list, function(blank) {
      colnames(blank)[1] <- "m.z"
      blank[, nominal_mass := floor(m.z + 0.5)]
      blank[, .(
        MDL = qt(input$confidence_level, df = .N - 1) * sd(I) + mean(I)
      ), by = nominal_mass]
    }) %>% rbindlist()
    
    MDL_master <- MDL_master[, .(MDL = round(mean(MDL))), by = nominal_mass]
    setnames(MDL_master, "nominal_mass", "m.z")
    
    # Initialize progress bar
    progress <- Progress$new(session, min = 0, max = length(sample_list))
    on.exit(progress$close())
    

    # Process samples
    processed_samples <- lapply(seq_along(sample_list), function(i) {
      progress$set(value = i, message = "Processing samples", detail = paste0("Sample ", i, " of ", length(sample_list)))
      sample <- sample_list[[i]]
      process_samples_MDL(
        sample      = sample_list[[i]], 
        sample_name = names(sample_list)[i], 
        MDL_master  = MDL_master
      )
      
    })
    
    names(processed_samples) <- names(sample_list)
    
    # Export processed_samples to the global environment
    assign("samples_MDL", processed_samples, envir = .GlobalEnv)
    removeNotification(notification_id)
    gc ()
    processed_samples
  })
  
  overview_data <- eventReactive(input$calculate, {
    req(samples_MDL())
    sample_list <- samples_data()
    processed_samples <- samples_MDL()
    
    overview <- data.table(
      Sample_Name = names(sample_list),
      Rows_Before = sapply(sample_list, nrow),
      Rows_After = sapply(processed_samples, nrow),
      Min_mz = sapply(processed_samples, function(x) min(x$m.z, na.rm = TRUE)),
      Max_mz = sapply(processed_samples, function(x) max(x$m.z, na.rm = TRUE))
    )
    
    return(overview)
  })
  
  output$status <- renderPrint({
    req(samples_MDL())
    paste("Processing complete. Samples available in local environment", length(samples_MDL()), "samples.")
  })
  
  output$overview <- renderTable({
    req(overview_data())
    overview_data()
  })
}


###############################################################################
#               Panel 2:  Functions & Shiny UI/Server Code                    #
#                      (Molecular Formula Generator)                          #
###############################################################################

isotope_combinations <- function(formulas_dt, mass_range,
                                 mass_C, mass_H, mass_O, mass_N, mass_S, mass_P) {
  # Construct a grid for all possible isotopes (within the defined maxima).
  isotope_grid <- CJ(
    O_18 = 0:max(formulas_dt$max_O18),
    C_13 = 0:max(formulas_dt$max_C13),
    S_34 = 0:max(formulas_dt$max_S34)
  )
  
  # Only keep relevant combinations:
  #  - Single extra isotope (O_18, S_34, or C_13)
  #    OR a double 13C (C_13 == 2) with no O_18 / S_34
  isotope_grid <- isotope_grid[
    (O_18 + S_34 + C_13 == 1) | (C_13 == 2 & O_18 == 0 & S_34 == 0)
  ]
  
  # Expand the formula set
  expanded_formulas <- formulas_dt[rep(seq_len(.N), each = nrow(isotope_grid))]
  expanded_isotopes <- isotope_grid[rep(seq_len(nrow(isotope_grid)), times = formulas_dt[ , .N])]
  combined_formulas <- cbind(expanded_formulas, expanded_isotopes)
  
  # Only valid if isotopes actually exist in the formula
  combined_formulas <- combined_formulas[
    (C_13 > 0 & O_18 == 0 & S_34 == 0) |
      ((S_34 > 0 & S > 0) | (O_18 > 0 & O > 0))
  ]
  
  # Recompute m/z for these isotopes
  combined_formulas[ ,
                     mz := C * mass_C + H * mass_H + O * mass_O + N * mass_N + S * mass_S + P * mass_P +
                       C_13 * (13.00335540 - mass_C) +
                       O_18 * (17.99915960 - mass_O) +
                       S_34 * (33.96786690 - mass_S)
  ]
  
  # Keep only those within the requested m/z range
  combined_formulas[mz >= mass_range[1] & mz <= mass_range[2]]
}


generate_formulas <- function(C_range = 1:50, H_range = 2:120, O_range = 0:50,
                              N_range = 0:4, S_range = 0:2, P_range = 0:1,
                              mass_range = c(50, 1000), HC = c( 0.2, 3), OC = c(0, 1.2), insert_isotopes = T) {
  
  # Define element masses in one place
  mass_C  <- 12
  mass_H  <- 1.00782503
  mass_O  <- 15.99491463
  mass_N  <- 14.00307400
  mass_S  <- 31.97207117
  mass_P  <- 30.97376203
  
  # Create the grid of C, N, S, P and apply basic filters
  dt <- CJ(C = C_range, N = N_range, S = S_range, P = P_range)[
    C > 0 &
      (N / C) <= 1.3 & (S / C) <= 0.8 & (P / C) <= 0.3 &
      !(N > 1 & (S + P > 0)) &
      !(N != 0 & S != 0 & P != 0) &
      !(S + P > 2) &
      !(N == 1 & (S > 1 | P > 1))
  ]
  
  # Precompute min and max for H and O based on rules
  dt[ , `:=`(
    H_min = pmax(ceiling(HC[1] * C), H_range[1]),
    H_max = pmin(floor(HC[2] * C), max(H_range)),
    O_max = pmin(floor(OC[2] * C), max(O_range))
  )]
  
  # Construct possible (H, O) combinations
  results <- dt[ , {
    if (H_min <= H_max) {
      H_values <- H_min:H_max
      O_values <- seq.int(0, O_max)
      H_O_dt <- CJ(H = H_values, O = O_values)[
        (H / C) >= HC[1] & (H / C) <= HC[2] & (O / C) >= OC[1] & (O / C) <= OC[2]
      ]
    } else {
      H_O_dt <- NULL
    }
    H_O_dt
  }, by = .(C, N, S, P)]
  
  # Compute DBE and valence, then subset
  results[ , `:=`(
    DBE    = 1 + (2 * C - H + N + P) / 2,
    valence = C * 4 + H * 1 + O * 2 + N * 3 + S * 2 + P * 5
  )]
  results <- results[
    DBE >= 0 & DBE %% 1 == 0 &
      valence %% 2 == 0
  ][ , c("DBE", "valence") := NULL]  # drop columns right after filtering
  
  # Compute final m/z
  results[ ,
           mz := C * mass_C + H * mass_H + O * mass_O + N * mass_N + S * mass_S + P * mass_P
  ]
  results <- results[mz >= mass_range[1] & mz <= mass_range[2]]
  
  # Insert isotopes if needed
  if (isTRUE(insert_isotopes)) {
    results[ , `:=`(
      max_O18 = pmin(1, O),
      max_C13 = pmin(2, C),
      max_S34 = pmin(1, S)
    )]
    
    # Reuse the pre-defined function
    results_isotopes <- isotope_combinations(
      formulas_dt = results,
      mass_range  = mass_range,
      mass_C      = mass_C,
      mass_H      = mass_H,
      mass_O      = mass_O,
      mass_N      = mass_N,
      mass_S      = mass_S,
      mass_P      = mass_P
    )
    results <- rbind(results, results_isotopes, use.names = TRUE, fill = TRUE)
    
  } else {
    # If not inserting isotopes, fill with zeros
    results[ , c("O_18", "C_13", "S_34") := 0]
  }
  
  # Final columns, replace NAs, and sort
  results <- results[ , .(
    C, H, O, N, S, P,
    C_13      = ifelse(is.na(C_13), 0, C_13),
    O_18      = ifelse(is.na(O_18), 0, O_18),
    S_34      = ifelse(is.na(S_34), 0, S_34),
    calculated_m.z = round(mz,8)
  )]
  
  setorder(results, calculated_m.z)
  gc()
  return(results)
}


# -- Panel 2 UI --
panel2_ui <- fluidPage(
  titlePanel("Molecular Formula Generator"),
  sidebarLayout(
    sidebarPanel(
      sliderInput("C_range", "C Range:", min = 1, max = 100, value = c(1, 50)),
      sliderInput("H_range", "H Range:", min = 1, max = 200, value = c(2, 120)),
      sliderInput("O_range", "O Range:", min = 0, max = 100, value = c(0, 50)),
      sliderInput("N_range", "N Range:", min = 0, max = 10, value = c(0, 4)),
      sliderInput("S_range", "S Range:", min = 0, max = 5, value = c(0, 2)),
      sliderInput("P_range", "P Range:", min = 0, max = 5, value = c(0, 1)),
      sliderInput("mass_range", "Mass Range:", min = 0, max = 2000, value = c(90, 1000)),
      sliderInput("HC", "H/C Range:", min = 0, max = 5, value = c(0.2, 3), step = 0.1),
      sliderInput("OC", "O/C Range:", min = 0, max = 4, value = c(0, 1.2), step = 0.1),
      checkboxInput("insert_isotopes", "Insert Isotopes", value = TRUE),
      actionButton("calc_button", "Calculate Formulas")
    ),
    mainPanel(
      DTOutput("results_table"),
      verbatimTextOutput("calc_message")
    )
  )
)

# -- Panel 2 Server --
panel2_server <- function(input, output, session) {
  
  results <- eventReactive(input$calc_button, {
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    
    out <- generate_formulas(
      C_range = input$C_range[1]:input$C_range[2],
      H_range = input$H_range[1]:input$H_range[2],
      O_range = input$O_range[1]:input$O_range[2],
      N_range = input$N_range[1]:input$N_range[2],
      S_range = input$S_range[1]:input$S_range[2],
      P_range = input$P_range[1]:input$P_range[2],
      mass_range = input$mass_range,
      HC = input$HC,
      OC = input$OC,
      insert_isotopes = input$insert_isotopes
    )
    removeNotification(notification_id)
    
    out
  })
  
  output$results_table <- renderDT({
    head(results())
  })
  
  observeEvent(input$calc_button, {
    assign("formulas", results(), envir = .GlobalEnv)
    output$calc_message <- renderText({
      "Calculation complete. Results saved to 'formulas' in your R environment."
    })
  })
}

###############################################################################
#               Panel 3:  Functions & Shiny UI/Server Code                    #
#                      (MZ Recalibration Tool)                                #
###############################################################################

# -- Panel 3 Functions --
formula_assignment <- function(formulas, dataset, ppm_tolerance = 0.5, 
                               ion = 1.007825032 + -1 * 0.00054857990907) {
  dataset$m.z_ion <- dataset$m.z
  dataset$m.z <- dataset$m.z + ion
  
  dataset[, `:=`(
    lower_limit = m.z * (1 - ppm_tolerance / 1e6),
    upper_limit = m.z * (1 + ppm_tolerance / 1e6)
  )]
  
  formulas[, `:=`(start = calculated_m.z, end = calculated_m.z)]
  
  setkey(formulas, start, end)
  setkey(dataset, lower_limit, upper_limit)
  final_matches <- foverlaps(formulas, dataset, 
                             by.x = c("start", "end"), 
                             by.y = c("lower_limit", "upper_limit"), 
                             type = "within", nomatch = 0)
  
  final_matches[, absolute_error := calculated_m.z - m.z]
  final_matches[, ppm := (absolute_error / m.z) * 1e6]
  
  filtered_matches <- final_matches[, .(m.z_ion, m.z, calculated_m.z, absolute_error, ppm,
                                        C, H, O, N, S, P , C_13, O_18, S_34, I, MDL)]
  
  unique_mz <- filtered_matches[, .N, by = m.z][N == 1, m.z]
  filtered_matches <- filtered_matches[m.z %in% unique_mz]
  gc()
  filtered_matches
}

calculate_connections <- function(dt, diffs = list(
  CH2 = c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0),
  H   = c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
)) {
  setorder(dt, C, H, O)
  dt[, index := .I]
  dt[, group := fifelse(N > 0 & P > 0, "NP", 
                        fifelse(N > 0 & (S > 0 | S_34 > 0), "NS", 
                                fifelse((S > 0 | S_34 > 0) & P > 0, "SP", 
                                        fifelse(N > 0 & S == 0 & P == 0 & S_34 == 0, "N", 
                                                fifelse((S > 0 | S_34 > 0) & N == 0 & P == 0, "S", 
                                                        fifelse(P > 0 & S == 0 & N == 0 & S_34 == 0, "P", 
                                                                fifelse(O > 0 & P == 0 & S == 0 & N == 0 & S_34 == 0, "CHO", 
                                                                        fifelse(O == 0 & P == 0 & S == 0 & N == 0 & S_34 == 0, "CH", "None"))))))))]
  
  results <- list()
  
  calculate_group_connections <- function(dt_group) {
    dt_group_unique <- dt_group
    group_results <- list()
    
    for (diff_name in names(diffs)) {
      diff_vector <- diffs[[diff_name]]
      
      diff_dt <- dt_group_unique[, .(
        C = C + diff_vector["C"],
        H = H + diff_vector["H"],
        O = O + diff_vector["O"],
        N = N + diff_vector["N"],
        S = S + diff_vector["S"],
        P = P + diff_vector["P"],
        from_index = index
      )]
      
      setkeyv(diff_dt, c("C", "H", "O", "N", "S", "P"))
      setkeyv(dt_group_unique, c("C", "H", "O", "N", "S", "P"))
      
      matched <- dt_group_unique[diff_dt, nomatch = 0L]
      
      if (nrow(matched) > 0) {
        connections <- matched[, .(
          from_index = from_index,
          to_index = index,
          connection_type = diff_name
        )]
        group_results[[diff_name]] <- connections
      }
    }
    
    all_group_connections <- rbindlist(group_results, use.names = TRUE, fill = TRUE)
    no_connections <- dt_group_unique[!index %in% unique(c(all_group_connections$from_index, all_group_connections$to_index)), .(
      from_index = index,
      to_index = NA,
      connection_type = "No Connection"
    )]
    
    all_group_connections <- rbind(all_group_connections, no_connections, fill = TRUE)
    return(all_group_connections)
  }
  
  for (grp in unique(dt$group)) {
    dt_group <- dt[group == grp]
    group_connections <- calculate_group_connections(dt_group)
    results[[grp]] <- group_connections
  }
  
  all_connections <- rbindlist(results, use.names = TRUE, fill = TRUE)
  Ak <- graph_from_data_frame(all_connections[!is.na(to_index)], directed = FALSE) %>% components()
  membership_dt <- data.table(index = as.integer(names(Ak$membership)), homologues_membership = Ak$membership)
  membership_dt[, homologues_membership := .N, by = homologues_membership]
  out <- merge(dt, membership_dt, by = "index", all.x = TRUE)
  out[is.na(homologues_membership), homologues_membership := 1]
  gc()
  return(out)
}

mz_recalibration <- function(formulas, dataset, ppm_tolerance = 0.5, 
                             ion = 1.007825032 + -1 * 0.00054857990907, 
                             S_MDL_limit = 1.5, hom_member_min = 1, showplot = TRUE) {
  filtered_matches <- formula_assignment(formulas, dataset, ppm_tolerance = ppm_tolerance, ion = ion)[P == 0]
  out <- filtered_matches[I / MDL > S_MDL_limit]
  
  if (nrow(out) > 20) {
    out <- calculate_connections(out)
    out <- out[homologues_membership >= hom_member_min]
  }
  
  if (nrow(out) > 20) {
    Q1 <- quantile(out$ppm, 0.25)
    Q3 <- quantile(out$ppm, 0.75)
    IQR <- Q3 - Q1
    bounds <- c(Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)
    out <- out[ppm > bounds[1] & ppm < bounds[2]]
    
    gam_model <- gam(ppm ~ s(m.z, bs = "cs", k = 4), data = out)
    
    correct_new_data <- function(m.z, gam_model) {
      new_data <- data.table(m.z)
      new_data[, predicted_drift_ppm := predict(gam_model, newdata = new_data)]
      new_data[, corrected_mz := m.z * (1 + predicted_drift_ppm / 1e6)]
      return(new_data)
    }
    
    pred <- correct_new_data(dataset$m.z, gam_model)
    dataset[, m.z := pred$corrected_mz]
    
    if (showplot) {
      pred <- subset(pred, m.z < max(filtered_matches$m.z))
      
      filtered_matches_2 <- formula_assignment(formulas, dataset, ppm_tolerance = ppm_tolerance, ion = ion)[P == 0]
      out2 <- filtered_matches_2[I / MDL > S_MDL_limit]
      out2 <- calculate_connections(out2)[homologues_membership >= hom_member_min]
      
      Q1_2 <- quantile(out2$ppm, 0.25)
      Q3_2 <- quantile(out2$ppm, 0.75)
      IQR_2 <- Q3_2 - Q1_2
      bounds_2 <- c(Q1_2 - 1.5 * IQR_2, Q3_2 + 1.5 * IQR_2)
      out2 <- out2[ppm > bounds_2[1] & ppm < bounds_2[2]]
      
      plot1 <- plot_ly() %>%
        add_trace(
          data = filtered_matches, x = ~m.z, y = ~ppm, type = 'scatter', mode = 'markers',
          marker = list(color = 'grey', size = 5), name = 'All assignments'
        ) %>%
        add_trace(
          data = out, x = ~m.z, y = ~ppm, type = 'scatter', mode = 'markers',
          marker = list(color = 'black', size = 5), name = 'Filtered assignments'
        ) %>%
        add_trace(
          data = out, x = pred$corrected_mz, y = pred$predicted_drift_ppm, type = 'scatter', mode = 'lines',
          line = list(color = 'red', width = 2), name = 'GAM Model'
        ) %>%
        layout(title = dataset$index[1], xaxis = list(title = "m/z"), yaxis = list(title = "ppm"))
      
      plot2 <- plot_ly() %>%
        add_trace(
          data = filtered_matches_2, x = ~m.z, y = ~ppm, type = 'scatter', mode = 'markers',
          marker = list(color = 'grey', size = 5), name = 'All assignments', showlegend = FALSE
        ) %>%
        add_trace(
          data = out2, x = ~m.z, y = ~ppm, type = 'scatter', mode = 'markers',
          marker = list(color = 'black', size = 5), name = 'Filtered assignments', showlegend = FALSE
        ) %>%
        layout(xaxis = list(title = "m/z"), yaxis = list(title = "ppm"))
      
      plot <- subplot(plot1, plot2, shareY = TRUE, titleX = TRUE, titleY = TRUE)
      print(paste0(dataset$index[1], " SSE before: ", round(sum(out$ppm^2), 2),
                   "| SSE after: ", round(sum(out2$ppm^2), 2)))
    } else {
      plot <- plot_ly()
    }
    dataset <- dataset[, .(m.z, I, MDL, ResPow, index)]
  } else {
    print(paste0(dataset$index[1], " Not enough points"))
    plot <- plot_ly()
  }
  
  print(paste0("Finished ", dataset$index[1]))
  gc()
  return(list(data = dataset, plot = plot))
}

# -- Panel 3 UI --
panel3_ui <- fluidPage(
  titlePanel("MZ Recalibration Tool"),
  sidebarLayout(
    sidebarPanel(
      numericInput("ppm_tolerance", "ppm tolerance:", value = 0.5, min = 0, step = 0.05),
      numericInput("S_MDL_limit", "S/MDL lower limit:", value = 2, min = 0, step = 0.1),
      numericInput("hom_member_min", "Homologue network length min:", value = 2, min = 1, step = 1),
      actionButton("calculate_mz", "Recalibrate"),
      # Removed the Previous/Next buttons; add a dynamic UI for the sample slider
      uiOutput("sample_slider_ui")
    ),
    mainPanel(
      tabsetPanel(
        tabPanel("Plot", plotlyOutput("mz_plot"))
      )
    )
  )
)

# -- Panel 3 Server --
panel3_server <- function(input, output, session) {
  
  # We'll store the list of recalibration results here
  recal_data <- reactiveVal(NULL)
  
  # Event to trigger recalibration of all "samples_MDL" with "formulas"
  observeEvent(input$calculate_mz, {
    
    # Make sure "samples_MDL" and "formulas" exist in .GlobalEnv
    if (!exists("samples_MDL", envir = .GlobalEnv)) {
      showNotification("Error: 'samples_MDL' not found in global environment.", type = "error")
      return(NULL)
    }
    if (!exists("formulas", envir = .GlobalEnv)) {
      showNotification("Error: 'formulas' not found in global environment.", type = "error")
      return(NULL)
    }
    
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    local_samples <- get("samples_MDL", envir = .GlobalEnv)
    local_formulas <- get("formulas", envir = .GlobalEnv)
    
    # Initialize progress bar
    progress <- Progress$new(session, min = 0, max = length(local_samples))
    on.exit(progress$close())
    
    # Recalibration
    out_list <- lapply(seq_along(local_samples), function(i) {
      progress$set(value = i, message = "Processing samples", detail = paste0("Sample ", i, " of ", length(local_samples)))
      mz_recalibration(subset(local_formulas, S == 0 & P == 0 ), local_samples[[i]],
                       ppm_tolerance = input$ppm_tolerance,
                       S_MDL_limit = input$S_MDL_limit,
                       hom_member_min = input$hom_member_min,
                       showplot = TRUE)
    })
    
    # Save the list of results
    recal_data(out_list)
    
    # Extract the data portion and assign to the global environment
    data_only_list <- lapply(out_list, function(x) x$data)
    assign("samples_MDL_recal_data", data_only_list, envir = .GlobalEnv)
    removeNotification(notification_id)
    showNotification("MZ Recalibration complete! 'samples_MDL_recal_data' saved globally.", type = "message")
  })
  
  # Dynamically generate the sample slider once recal_data() is available
  output$sample_slider_ui <- renderUI({
    req(recal_data())
    sliderInput(
      "sample_slider",
      "Select Sample:",
      min = 1,
      max = length(recal_data()),
      value = 1,
      step = 1
    )
  })
  
  # Reactive value for the current sample index
  current_sample <- reactiveVal(1)
  
  # Update current sample whenever the slider value changes
  observeEvent(input$sample_slider, {
    req(recal_data())
    current_sample(input$sample_slider)
  })
  
  # Render the plot for the currently selected sample
  output$mz_plot <- renderPlotly({
    req(recal_data())
    idx <- current_sample()
    if (idx > 0 && idx <= length(recal_data())) {
      recal_data()[[idx]]$plot
    }
  })
}



###############################################################################
#               Panel 4:  Functions & Shiny UI/Server Code                    #
#                      (Merge m/z Values)                                     #
###############################################################################

# -- Panel 4 Functions --
merge_mz_values <- function(dt, ppm_tolerance) {
  
  
  # Rename columns d
  setnames(dt, old = colnames(dt)[1], new = "mz")
  setnames(dt, old = colnames(dt)[3], new = "MDL")
  
  # Sort by m/z
  
  setorder(dt, mz)
  
  # Compute difference in ppm between consecutive m/z
  dt[, diff_ppm := (mz - shift(mz, type = "lag")) / shift(mz, type = "lag") * 1e6]
  # Replace the first NA with Inf (equivalent to c(Inf, diff(mz))/mz * 1e6)
  dt[is.na(diff_ppm), diff_ppm := Inf]
  
  # Identify groups whose differences exceed ppm_tolerance
  dt[, group := cumsum(diff_ppm > ppm_tolerance)]
  
  # Calculate the weighted mean m/z and other values 
  merged <- dt[, {
    sqrt_I <- sqrt(I)
    sum_sqrt_I <- sum(sqrt_I)
    .(
      merged_mz = sum(mz * sqrt_I) / sum_sqrt_I,
      mean_MDL  = MDL[1],            #MDL should be the same accross all samples.                   
      SE        = sd(mz) / (sum(mz * sqrt_I) / sum_sqrt_I) * 1e6
    )
  }, by = group]
  
  # Update-join  to add columns back
  dt[merged, on = "group", `:=`(
    merged_mz = i.merged_mz,
    mean_MDL  = i.mean_MDL,
    SE        = i.SE
  )]
  
  # Remove duplicates by selecting the first row per group and index
  dt2 <- dt[, .SD[1], keyby = .(group, index)]
  
  # Reshape to wide format; each index becomes a column
  dt_wide <- dcast(
    dt2,
    merged_mz + mean_MDL + SE ~ index,
    value.var = "I",
    fill = NA
  )
  
  # Rename columns for the final output
  setnames(dt_wide, old = c("merged_mz", "mean_MDL"), new = c("m.z", "MDL"))
  gc()
  return(dt_wide)
}


# -- Panel 4 UI --
panel4_ui <- fluidPage(
  titlePanel("Merge m/z Values"),
  sidebarLayout(
    sidebarPanel(
      numericInput("ppm_tolerance_merge", "PPM Tolerance:", value = 0.5, min = 0, step = 0.1),
      actionButton("calculate_merge", "Merge samples")
    ),
    mainPanel(
      verbatimTextOutput("status_merge"),
      DTOutput("results_table_merge")
    )
  )
)

# -- Panel 4 Server --
panel4_server <- function(input, output, session) {
  
  observeEvent(input$calculate_merge, {
    # Ensure samples_MDL_recal_data exists
    if (!exists("samples_MDL_recal_data", envir = .GlobalEnv)) {
      output$status_merge <- renderText("Error: 'samples_MDL_recal_data' is not found in the global environment.")
      return(NULL)
    }
    
    # Perform the calculation
    output$status_merge <- renderText("Calculating...")
    notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
    
    
    tryCatch({
      local_samples <- get("samples_MDL_recal_data", envir = .GlobalEnv)
      combined_dt <- rbindlist(local_samples, fill = TRUE)
      result_dt <- merge_mz_values(combined_dt, ppm_tolerance = input$ppm_tolerance_merge)
      
      # Assign result to global environment
      assign("merged_samples", result_dt, envir = .GlobalEnv)
      removeNotification(notification_id)
      output$status_merge <- renderText("Calculation complete! Check the global environment for 'merged_samples'. Table below shows the header.")
    }, error = function(e) {
      output$status_merge <- renderText(paste("Error:", e$message))
    })
    output$results_table_merge <- renderDT({
      head(result_dt)
    })
    
  })
}

###############################################################################
#               Panel 5:  Functions & Shiny UI/Server Code                    #
#              (Formula Assignment and Isotope Calculation)                   #
###############################################################################

# -- Panel 5 Functions --
# Compute isotope deviance
isotope_deviance <- function(intensity_parent, intensity_child,
                             number_of_atoms, q, p, number_of_isotopes = 1) {
  expected_intensity_ratio <- dbinom(number_of_isotopes, number_of_atoms, q) /
    dbinom(number_of_atoms, number_of_atoms, p)
  ratio <- intensity_child / intensity_parent
  
  # Weighted mean of ratio, then scaled relative to expected_intensity_ratio
  rdeviance_weighted <- ((weighted.mean(ratio, intensity_parent, na.rm = TRUE) /
                            expected_intensity_ratio) - 1) * 1000
  return(round(rdeviance_weighted))
}

# Compute a formula string from element counts
construct_formula <- function(elements) {
  # e.g., elements = list(C=6, H=12, O=6, ...)
  # each gets turned into "C6", "H12", etc., omitting the number if == 1
  formula_parts <- paste0(names(elements),
                          ifelse(elements == 1, "", elements))
  formula <- paste(formula_parts[elements > 0], collapse = "")
  return(formula)
}

# Identify group connections for a single group
calculate_group_connections <- function(dt_group, diffs) {
  group_results <- list()
  
  # For each type of difference (CH2, H, etc.) 
  for (diff_name in names(diffs)) {
    diff_vector <- diffs[[diff_name]]
    diff_dt <- dt_group[, .(
      C = C + diff_vector["C"],
      H = H + diff_vector["H"],
      O = O + diff_vector["O"],
      N = N + diff_vector["N"],
      S = S + diff_vector["S"],
      P = P + diff_vector["P"],
      from_index = index
    )]
    
    # Match the diff_dt to dt_group by the new formula
    setkeyv(diff_dt, c("C", "H", "O", "N", "S", "P"))
    setkeyv(dt_group, c("C", "H", "O", "N", "S", "P"))
    
    matched <- dt_group[diff_dt, nomatch = 0L]
    
    if (nrow(matched) > 0) {
      group_results[[diff_name]] <- matched[, .(
        from_index = from_index,
        to_index = index,
        connection_type = diff_name
      )]
    }
  }
  
  # Combine all connections for this group
  all_group_connections <- data.table::rbindlist(group_results, use.names = TRUE, fill = TRUE)
  
  # Tag any formula with no connections
  no_connections <- dt_group[
    !index %in% unique(c(all_group_connections$from_index, all_group_connections$to_index)),
    .(from_index = index, to_index = NA, connection_type = "No Connection")
  ]
  all_group_connections <- rbind(all_group_connections, no_connections, fill = TRUE)
  
  return(all_group_connections)
}

# --- Main Functions ---

# Calculate isotopes
calculate_isotopes <- function(filtered_matches, dataset) {
  
  # Identify intensity columns
  intensity_cols <- setdiff(names(dataset), c("m.z", "MDL", "SE", "ResPow", "m.z_ion", "index"))
  
  # Compute combined intensities (rowMeans if >1 column, or single column)
  if (length(intensity_cols) > 1) {
    intensities <- dataset[, .(m.z, intensities = rowMeans(.SD, na.rm = TRUE)), 
                           .SDcols = intensity_cols]
  } else {
    intensities <- dataset[, .(m.z, intensities = get(intensity_cols))]
  }
  
  # Merge intensities onto filtered_matches
  filtered_matches <- merge(filtered_matches, intensities, 
                            by.x = "m.z", by.y = "m.z", all.x = TRUE)
  
  # Split into parent vs. child isotopes
  parent_all     <- filtered_matches[C_13 == 0 & O_18 == 0 & S_34 == 0]
  child_C_1_all  <- filtered_matches[C_13 == 1 & O_18 == 0 & S_34 == 0]
  child_C_2_all  <- filtered_matches[C_13 == 2 & O_18 == 0 & S_34 == 0]
  child_O_all    <- filtered_matches[C_13 == 0 & O_18 == 1 & S_34 == 0]
  child_S_all    <- filtered_matches[C_13 == 0 & O_18 == 0 & S_34 == 1]
  
  # Merge them parent->child
  result_C1 <- merge(parent_all, child_C_1_all,
                     by = c("C", "H", "O", "N", "S", "P"),
                     suffixes = c("_parent", "_child"))
  result_C2 <- merge(parent_all, child_C_2_all,
                     by = c("C", "H", "O", "N", "S", "P"),
                     suffixes = c("_parent", "_child"))
  result_O  <- merge(parent_all, child_O_all,
                     by = c("C", "H", "O", "N", "S", "P"),
                     suffixes = c("_parent", "_child"))
  result_S  <- merge(parent_all, child_S_all,
                     by = c("C", "H", "O", "N", "S", "P"),
                     suffixes = c("_parent", "_child"))
  
  # Filter out where parent intensities <= child intensities
  # ( only keep lines where intensities_parent > intensities_child)
  result_C1 <- result_C1[intensities_parent > intensities_child]
  result_C2 <- result_C2[intensities_parent > intensities_child]
  result_O  <- result_O[intensities_parent > intensities_child]
  result_S  <- result_S[intensities_parent > intensities_child]
  
  # Calculate deviance in each isotopic group
  col_parent <- "intensities_parent"
  col_child  <- "intensities_child"
  
  #  use row-by-row by=seq_len(nrow(.)) 
  result_C1[, isotope_deviance_C_13_1 := isotope_deviance(
    as.numeric(get(col_parent)), as.numeric(get(col_child)),
    number_of_atoms = C, q = 0.0108, p = 1 - 0.0108, number_of_isotopes = 1
  ), by = seq_len(nrow(result_C1))]
  
  result_C2[, isotope_deviance_C_13_2 := isotope_deviance(
    as.numeric(get(col_parent)), as.numeric(get(col_child)),
    number_of_atoms = C, q = 0.0108, p = 1 - 0.0108, number_of_isotopes = 2
  ), by = seq_len(nrow(result_C2))]
  
  result_O[, isotope_deviance_O_18 := isotope_deviance(
    as.numeric(get(col_parent)), as.numeric(get(col_child)),
    number_of_atoms = O, q = 0.00205, p = 1 - 0.00205, number_of_isotopes = 1
  ), by = seq_len(nrow(result_O))]
  
  result_S[, isotope_deviance_S_34 := isotope_deviance(
    as.numeric(get(col_parent)), as.numeric(get(col_child)),
    number_of_atoms = S, q = 0.0437, p = 1 - 0.0437, number_of_isotopes = 1
  ), by = seq_len(nrow(result_S))]
  
  # Combine parent + isotopic children
  #full_results <- rbind(parent_all, result_C1, result_C2, result_O, result_S, fill = TRUE)
  
  # Identify columns with '_parent' and '_child'
  parent_cols <- grep("_parent$", colnames(result_C1), value = TRUE)
  child_cols <- grep("_child$", colnames(result_C1), value = TRUE)
  
  # Combine with C H O N S P columns (which are common)
  common_cols <- c("C", "H", "O", "N", "S", "P")
  
  # Create separate data.tables for parent and child
  parent_C1 <- result_C1[, c(common_cols, parent_cols,"isotope_deviance_C_13_1"), with = FALSE]
  result_C1 <- result_C1[, c(common_cols, child_cols,"isotope_deviance_C_13_1"), with = FALSE]
  
  parent_C2 <- result_C2[, c(common_cols, parent_cols,"isotope_deviance_C_13_2"), with = FALSE]
  result_C2 <- result_C2[, c(common_cols, child_cols,"isotope_deviance_C_13_2"), with = FALSE]
  
  parent_O <- result_O[, c(common_cols, parent_cols,"isotope_deviance_O_18"), with = FALSE]
  result_O <- result_O[, c(common_cols, child_cols,"isotope_deviance_O_18"), with = FALSE]
  
  parent_S <- result_S[, c(common_cols, parent_cols,"isotope_deviance_S_34"), with = FALSE]
  result_S <- result_S[, c(common_cols, child_cols,"isotope_deviance_S_34"), with = FALSE]
  
  # remove the '_parent' and '_child' suffixes for better readability
  setnames(parent_C1, gsub("_parent$", "", colnames(parent_C1)))
  setnames(result_C1, gsub("_child$", "", colnames(result_C1)))
  setnames(parent_C2, gsub("_parent$", "", colnames(parent_C2)))
  setnames(result_C2, gsub("_child$", "", colnames(result_C2)))
  setnames(parent_O, gsub("_parent$", "", colnames(parent_O)))
  setnames(result_O, gsub("_child$", "", colnames(result_O)))
  setnames(parent_S, gsub("_parent$", "", colnames(parent_S)))
  setnames(result_S, gsub("_child$", "", colnames(result_S)))
  
  parent_C1[, intensities := NULL]
  parent_C2[, intensities := NULL]
  parent_O[, intensities := NULL]
  parent_S[, intensities := NULL]
  result_C1[, intensities := NULL]
  result_C2[, intensities := NULL]
  result_O[, intensities := NULL]
  result_S[, intensities := NULL]
  
  parent_all[, intensities := NULL]
  
  
  isotopes <-merge(result_C1, result_C2, 
                   by = colnames(result_C1)[-ncol(result_C1)], all = T) 
  
  isotopes <- merge(isotopes, result_O, 
                    by = colnames(parent_C1)[-ncol(parent_C1)], all = T)
  isotopes <- merge(isotopes, result_S, 
                    by = colnames(parent_C1)[-ncol(parent_C1)], all = T)
  
  out <- rbind(parent_all, isotopes, fill =T)
  gc()
  return(out)
}

# Calculate homologous connections (panel 5)
calculate_connections_panel5 <- function(dt, diffs = list(
  CH2 = c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0),
  H   = c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
)) {
  data.table::setorder(dt, C, H, O)
  dt[, index := .I]
  
  # Group assignment
  dt[, group := fifelse(N > 0 & P > 0, "NP",
                        fifelse(N > 0 & (S > 0 | S_34 > 0), "NS",
                                fifelse((S > 0 | S_34 > 0) & P > 0, "SP",
                                        fifelse(N > 0 & S == 0 & P == 0 & S_34 == 0, "N",
                                                fifelse((S > 0 | S_34 > 0) & N == 0 & P == 0, "S",
                                                        fifelse(P > 0 & S == 0 & N == 0 & S_34 == 0, "P",
                                                                fifelse(O > 0 & P == 0 & S == 0 & N == 0 & S_34 == 0, "CHO",
                                                                        fifelse(O == 0 & P == 0 & S == 0 & N == 0 & S_34 == 0, "CH", "None"))))))))]
  
  # Calculate connections in each group
  results <- list()
  for (grp in unique(dt$group)) {
    dt_group <- dt[group == grp]
    grp_con <- calculate_group_connections(dt_group, diffs)
    results[[grp]] <- grp_con
  }
  
  # Combine all group connections
  all_connections <- data.table::rbindlist(results, use.names = TRUE, fill = TRUE)
  
  # Graph-based approach to membership
  Ak <- igraph::graph_from_data_frame(all_connections[!is.na(to_index)], directed = FALSE) %>%
    igraph::components()
  membership_dt <- data.table::data.table(index = as.integer(names(Ak$membership)),
                                          homologues_membership = Ak$membership)
  membership_dt[, homologues_membership := .N, by = homologues_membership]
  
  out <- merge(dt, membership_dt, by = "index", all.x = TRUE)
  out[is.na(homologues_membership), homologues_membership := 1]
  
  # We typically don't need explicit garbage collection calls repeatedly
  return(out)
}

# Main formula assignment that calls the above functions
formula_assignment_multi_intensity <- function(
    formulas, dataset, ppm_tolerance = 0.5,
    ion = 1.007825032 + -1 * 0.00054857990907,
    threshold = 1000, return_likeliest = TRUE,
    delete_singlets = TRUE, delete_MF_without_connection = TRUE,
    homologues_network = list(
      CH2 = c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0),
      H   = c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
    )
) {
  # Adjust m.z by the chosen ion mass
  dataset$m.z_ion <- dataset$m.z
  dataset$m.z     <- dataset$m.z + ion
  
  # Generate tolerance columns
  dataset[, `:=`(lower_limit = m.z * (1 - ppm_tolerance / 1e6),
                 upper_limit = m.z * (1 + ppm_tolerance / 1e6))]
  
  # Prepare formula data and set keys for overlap
  formulas[, `:=`(start = calculated_m.z, end = calculated_m.z)]
  data.table::setkey(formulas, start, end)
  data.table::setkey(dataset, lower_limit, upper_limit)
  
  # Overlap join
  all_matches <- foverlaps(
    formulas, dataset, 
    by.x = c("start", "end"),
    by.y = c("lower_limit", "upper_limit"),
    type = "within", nomatch = 0
  )
  dataset[, `:=`(lower_limit = NULL, upper_limit = NULL)]
  
  # Calculate error & filter columns
  all_matches[, absolute_error := calculated_m.z - m.z]
  all_matches[, ppm := (absolute_error / m.z) * 1e6]
  
  filtered_matches <- all_matches[, .(
    m.z_ion, m.z, calculated_m.z, absolute_error, ppm,
    C, H, O, N, S, P, C_13, O_18, S_34
  )]
  
  # 1) Isotope peak verification
  filtered_matches <- calculate_isotopes(filtered_matches, dataset = dataset)
  
  # 2) Homologous series calculation
  filtered_matches <- calculate_connections_panel5(filtered_matches, diffs = homologues_network)
  filtered_matches[, index := NULL]
  
  # Threshold test
  filtered_matches[, isotope_below_threshold := (
    isotope_deviance_C_13_1 < threshold |
      isotope_deviance_C_13_2 < threshold |
      isotope_deviance_O_18   < threshold |
      isotope_deviance_S_34   < threshold
  )]
  
  # Return only best match per measured m/z if requested
  if (return_likeliest) {
    filtered_matches[, abs_ppm := abs(ppm)]
    data.table::setorder(filtered_matches, m.z, -isotope_below_threshold,
                         -homologues_membership, abs_ppm)
    filtered_matches <- filtered_matches[, .SD[1], by = m.z]
    filtered_matches[, c("abs_ppm", "homologues_membership") := NULL]
    
    # Keep only isotopes with deviance below threshold
    filtered_matches <- subset(filtered_matches,
                               (C_13 == 0 | isotope_below_threshold == TRUE) &
                                 (O_18 == 0 | isotope_below_threshold == TRUE) &
                                 (S_34 == 0 | isotope_below_threshold == TRUE)
    )
    
    # Recompute connections
    filtered_matches <- calculate_connections_panel5(
      filtered_matches, diffs = homologues_network
    )
  }
  
  # 3) Construct molecular formula and compute other metrics
  filtered_matches[, MF := construct_formula(
    list(C = C, H = H, O = O, N = N, S = S, P = P)
  ), by = 1:nrow(filtered_matches)]
  
  filtered_matches[, AI_mod := (1 + C - 0.5 * O - S - 0.5 * (H + N + P)) /
                     (C - 0.5 * O - S - N - P)]
  filtered_matches[, AI_mod := ifelse(AI_mod < 0 | is.infinite(AI_mod), 0, AI_mod)]
  filtered_matches <- filtered_matches[AI_mod <= 1]
  
  filtered_matches[, NOSC := (-(4*C + H - 3*N - 2*O + 5*P - 2*S) / C) + 4]
  filtered_matches[, `:=`(
    O.C = O/C, H.C = H/C, N.C = N/C, S.C = S/C, P.C = P/C
  )]
  
  # Simple classification
  filtered_matches[, class := fifelse(
    O.C > 0 & O.C <= 0.3 & H.C > 1.5 & H.C <= 2.5, "Lipid",
    fifelse(
      O.C <= 0.125 & H.C >= 1 & H.C <= 1.5 & AI_mod > 0.5, "Unsaturated hydrocarbon",
      fifelse(
        O.C > 0.3 & O.C <= 0.55 & H.C > 1.5 & H.C <= 2.3, "Protein",
        fifelse(
          O.C > 0.55 & O.C <= 0.7 & H.C > 1.5 & H.C <= 2.2, "Aminosugar",
          fifelse(
            O.C > 0.7 & O.C <= 1.05 & H.C > 1.5 & H.C <= 2.2, "Carbohydrate",
            fifelse(
              AI_mod >= 0.67, "Condensed hydrocarbon",
              fifelse(
                AI_mod < 0.67 & AI_mod > 0.5 & O.C > 0.125, "Aromatic",
                fifelse(
                  O.C > 0.125 & AI_mod <= 0.5 & H.C <= 1.5,
                  "Highly unsaturated", "Unassigned"
                )
              )
            )
          )
        )
      )
    )
  )]
  
  # Reorder/filter columns
  filter_cols <- c(
    "m.z_ion", "m.z", "calculated_m.z", "absolute_error", "ppm", "MF",
    "group", "class", "C", "H", "O", "N", "S", "P", "C_13", "O_18", "S_34",
    "H.C", "O.C", "N.C", "S.C", "P.C", "AI_mod", "NOSC", "homologues_membership",
    "isotope_deviance_C_13_1", "isotope_deviance_C_13_2",
    "isotope_deviance_O_18", "isotope_deviance_S_34", "isotope_below_threshold"
  )
  filtered_matches <- filtered_matches[, ..filter_cols]
  
  # Merge original dataset columns back in and track presence
  dataset[, m.z := NULL]
  filtered_matches <- merge(filtered_matches, dataset, 
                            by.x = "m.z_ion", by.y = "m.z_ion", all.x = TRUE)
  filtered_matches[, present_in := rowSums(!is.na(.SD)),
                   .SDcols = (ncol(filtered_matches) - length(filter_cols)):ncol(filtered_matches)]
  
  # Move `present_in` column to just after the filter_cols
  filter_col_names <- names(filtered_matches)[1:length(filter_cols)]
  setcolorder(filtered_matches, c(filter_col_names, "present_in",
                                  setdiff(names(filtered_matches),
                                          c(filter_col_names, "present_in"))))
  
  # Delete singlets if chosen
  if (delete_singlets) {
    filtered_matches <- subset(filtered_matches, present_in > 1)
  }
  
  # Possibly delete MF without a homologous connection
  if (delete_MF_without_connection) {
    # Recalculate homologues membership after removing singlets
    if (delete_singlets) {
      temp <- copy(filtered_matches)
      temp[, homologues_membership := NULL]
      filtered_matches$homologues_membership <- calculate_connections_panel5(
        temp, diffs = homologues_network
      )$homologues_membership
    }
    filtered_matches <- subset(filtered_matches, homologues_membership > 1)
  }
  
  setorder(filtered_matches, m.z)
  gc()
  return(filtered_matches)
}


# -- Panel 5 UI --
panel5_ui <- fluidPage(
  titlePanel("Formula Assignment and Isotope Calculation"),
  sidebarLayout(
    sidebarPanel(
      numericInput("ppm_tolerance_panel5", "ppm tolerance:", value = 0.3, min = 0, step = 0.1),
      numericInput("threshold_panel5", "Isotope deviance threshold:", value = 1000, min = 0, step = 1),
      checkboxInput("return_likeliest_panel5", "Return Likeliest", value = TRUE),
      checkboxInput("delete_singlets", "Delete Singlets", value = TRUE),
      checkboxInput("delete_MF_without_connection", "Delete MF without Connection", value = TRUE),
      checkboxGroupInput("homologues_network_panel5", "Select Homologues Network:", 
                         choices = list(
                           "CH2"  = "CH2",
                           "CH2O" = "CH2O",
                           "C2HO" = "C2HO",
                           "CO2"  = "CO2",
                           "H2O"  = "H2O",
                           "H"    = "H",
                           "O"    = "O",
                           "NH3"  = "NH3"
                         ),
                         selected = c("CH2",  "O")),
      actionButton("calculate_panel5", "Assign Formulas"),
      textOutput("status_panel5")
    ),
    mainPanel(
      DTOutput("results_table_panel_5")
    )
  )
)

# -- Panel 5 Server --
panel5_server <- function(input, output, session) {
  
  crosstab <- reactiveVal(NULL)
  
  observeEvent(input$calculate_panel5, {
    output$status_panel5 <- renderText("Calculating...")
    
    # Ensure we have 'formulas' and 'merged_samples' in global environment
    if (!exists("formulas", envir = .GlobalEnv)) {
      output$status_panel5 <- renderText("Error: 'formulas' is not found in the global environment.")
      return(NULL)
    }
    if (!exists("merged_samples", envir = .GlobalEnv)) {
      output$status_panel5 <- renderText("Error: 'merged_samples' is not found in the global environment.")
      return(NULL)
    }
    
    local_formulas <- get("formulas", envir = .GlobalEnv)
    local_water_dt <- get("merged_samples", envir = .GlobalEnv)
    
    tryCatch({
      selected_homologues <- list()
      if ("CH2"  %in% input$homologues_network_panel5) selected_homologues$CH2  <- c(C = 1, H = 2, O = 0, N = 0, S = 0, P = 0)
      if ("CH2O" %in% input$homologues_network_panel5) selected_homologues$CH2O <- c(C = 1, H = 2, O = 1, N = 0, S = 0, P = 0)
      if ("C2HO" %in% input$homologues_network_panel5) selected_homologues$C2HO <- c(C = 2, H = 1, O = 1, N = 0, S = 0, P = 0)
      if ("CO2"  %in% input$homologues_network_panel5) selected_homologues$CO2  <- c(C = 1, H = 0, O = 2, N = 0, S = 0, P = 0)
      if ("H2O"  %in% input$homologues_network_panel5) selected_homologues$H2O  <- c(C = 0, H = 2, O = 1, N = 0, S = 0, P = 0)
      if ("H"    %in% input$homologues_network_panel5) selected_homologues$H    <- c(C = 0, H = 1, O = 0, N = 0, S = 0, P = 0)
      if ("O"    %in% input$homologues_network_panel5) selected_homologues$O    <- c(C = 0, H = 0, O = 1, N = 0, S = 0, P = 0)
      if ("NH3"  %in% input$homologues_network_panel5) selected_homologues$NH3  <- c(C = 0, H = 3, O = 0, N = 1, S = 0, P = 0)
      
      notification_id <- showNotification("Calculating...", type = "message", duration = NULL)
      
      result <- formula_assignment_multi_intensity(
        formulas          = local_formulas,
        dataset           = local_water_dt,
        ppm_tolerance     = input$ppm_tolerance_panel5,
        threshold         = input$threshold_panel5,
        return_likeliest  = input$return_likeliest_panel5,
        homologues_network= selected_homologues,
        delete_singlets   = input$delete_singlets,
        delete_MF_without_connection = input$delete_MF_without_connection
      )
      
      crosstab(result)
      
      assign("crosstab", result, envir = .GlobalEnv)
      output$status_panel5 <- renderText("Calculation complete. Results saved to 'crosstab' in your R environment.")
      removeNotification(notification_id)
    }, error = function(e) {
      output$status_panel5 <- renderText(paste("Error:", e$message))
    })
  })
  
  output$results_table_panel_5 <- renderDT({
    crosstab()
  })
}


###############################################################################
#                             COMBINED UI & SERVER                             #
###############################################################################

# Combine all panel UIs into one "navbarPage".
# Then define one server that calls each panel’s server function within its own scope.

ui <- navbarPage(
  title = "Formula Asssigner",
  
  tabPanel(
    "MDL",
    panel1_ui
  ),
  
  tabPanel(
    "Formula Template",
    panel2_ui
  ),
  
  tabPanel(
    "Recalibration",
    panel3_ui
  ),
  
  tabPanel(
    "Sample Merging",
    panel4_ui
  ),
  
  tabPanel(
    "Formula Assignment",
    panel5_ui
  )
)

# A single server function that calls each panel's server logic
server <- function(input, output, session) {
  callModule(module = panel1_server, id = NULL)
  callModule(module = panel2_server, id = NULL)
  callModule(module = panel3_server, id = NULL)
  callModule(module = panel4_server, id = NULL)
  callModule(module = panel5_server, id = NULL)
}

# Launch the unified Shiny app
shinyApp(ui, server)


# 
# #data processing
# sub <- crosstab
# #sub[, present_in := rowSums(!is.na(.SD)), .SDcols = 33:77]
# sub[, present_in_percent := (present_in / 45) * 100]
# sub1 <- subset(sub, sub$homologues_membership >4 & sub$present_in >1)
# #sub1 <- subset(sub1, sub1$`masslistsESI_neg_Nelha_25ppm_200scans_0-1acc_mid_20200812_000001` >0)
# plot <- vk_plot_hist(list(sub1))#, sizes = list(sqrt(sub1$present_in_percent)))
# plot
# 
# plot_mass_spectrum(dat = list(as.data.frame(sub1)), intensity_colum = 33, norm = F)



#reduce overhead: button to remove original files after mdl calculation?
#rewrite recalibration function to not use lapply and instead only data.table syntax.
#try to remove lapply where possible to remove overhead
